{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mNo se pudo iniciar el Kernel. \n",
      "\u001b[1;31mNo se ha podido iniciar el Kernel \"seriesTemporales (Python 3.12.3)\" debido a un tiempo de espera para que se utilicen los puertos. \n",
      "\u001b[1;31mVer Jupyter <a href='command:jupyter.viewOutput'>log</a> para más detalles."
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LECTURA DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir('/Users/maxiabdala/Documents/Python/repositorio Maxi/series_temporales_maxi/trabajo_final/codigo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vemos los archivos de audio\n",
    "data_folder = os.path.join('data', 'train')  # carpeta del training set\n",
    "classes_folders = os.listdir(data_folder)                   # carpeta de cada clase\n",
    "\n",
    "# Creamos un diccionario para cada clase donde pondremos los audios\n",
    "data = {}\n",
    "for c in classes_folders:\n",
    "    if c[0] != '.':\n",
    "        data[c] = data.get(c, []) # agregamos\n",
    "\n",
    "# Llenamos una lista para cada clase con los datos\n",
    "b=0\n",
    "for c in classes_folders:\n",
    "    if c[0] != '.':\n",
    "        for f in os.listdir(os.path.join(data_folder, c)):\n",
    "            path = os.path.join(data_folder, c, f)\n",
    "            audio, sr = librosa.load(os.path.join(data_folder, c, f) , sr=None)  # leemos el audio como numpy array\n",
    "            duracion = librosa.get_duration(y=audio, sr=sr)\n",
    "            if (b):\n",
    "              if (duracion<men): men=duracion\n",
    "            else:\n",
    "              men=duracion\n",
    "              b=1\n",
    "            data[c].append(audio)   # no guardamos el samplerate porque todos son iguales\n",
    "\n",
    "# Inspección de los datos\n",
    "\n",
    "for k in data.keys():\n",
    "    print(f'La clase {k} tiene {len(data[k])} elementos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESPECTOGRAMAS CON STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tasa de muestreo que vamos a asumir para todos los audios\n",
    "sampling_rate = 22050/2\n",
    "\n",
    "def compute_stft_spectrogram(audio_array, sampling_rate):\n",
    "    \"\"\"\n",
    "    Compute STFT Spectrogram for a given audio array.\n",
    "    \n",
    "    Args:\n",
    "    - audio_array (np.ndarray): Array containing audio data.\n",
    "    - sr (int): Sampling rate of the audio file.\n",
    "    \n",
    "    Returns:\n",
    "    - S_DB (np.ndarray): STFT spectrogram in decibels.\n",
    "    \"\"\"\n",
    "    S = librosa.stft(y=audio_array, n_fft=sampling_rate, hop_length=400, window='hann')# probar con 'hann' o 'hamming'\n",
    "    S_DB = librosa.amplitude_to_db(np.abs(S), ref=np.max)\n",
    "    return S_DB\n",
    "\n",
    "# Diccionario para almacenar los espectrogramas STFT\n",
    "stft_spectrograms = {}\n",
    "\n",
    "# Calcular los espectrogramas STFT para cada clase y cada archivo de audio\n",
    "for k, v in data.items():\n",
    "    stft_spectrograms[k] = []\n",
    "    for audio_array in v:\n",
    "        stft_spec = compute_stft_spectrogram(audio_array, sampling_rate)\n",
    "        stft_spectrograms[k].append(stft_spec)\n",
    "\n",
    "# Verificar la cantidad de espectrogramas calculados por clase\n",
    "for k, v in stft_spectrograms.items():\n",
    "    print(f'Clase {k}: {len(v)} espectrogramas STFT')\n",
    "\n",
    "# Función para graficar los espectrogramas STFT de una clase específica\n",
    "def plot_stft_spectrograms(stft_spectrograms, class_name, sr):\n",
    "    num_specs = len(stft_spectrograms[class_name])\n",
    "    fig, axs = plt.subplots(1, num_specs, figsize=(25, 5))\n",
    "    fig.suptitle(f'Espectrogramas STFT para la Clase {class_name}', fontsize=16)\n",
    "    \n",
    "    for i, stft_spec in enumerate(stft_spectrograms[class_name]):\n",
    "        img = axs[i].imshow(stft_spec, cmap='viridis', origin='lower', aspect='auto')\n",
    "        axs[i].set_title(f'Espectrograma {i + 1}')\n",
    "        axs[i].set_xlabel('Tiempo')\n",
    "        axs[i].set_ylabel('Frecuencia')\n",
    "        \n",
    "        # Calcular marcas de tiempo\n",
    "        num_time_bins = stft_spec.shape[1]\n",
    "        duration = len(data[class_name][i]) / sr\n",
    "        time_ticks = np.linspace(0, duration, num_time_bins)\n",
    "        \n",
    "        # Configurar las marcas de tiempo en el eje x\n",
    "        axs[i].set_xticks(np.linspace(0, num_time_bins, 3))\n",
    "        axs[i].set_xticklabels([f'{t:.2f}' for t in np.linspace(0, duration, 3)])\n",
    "        \n",
    "        fig.colorbar(img, ax=axs[i], format='%+2.0f dB')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.85)  # Ajustar el espacio para el título\n",
    "    plt.show()\n",
    "\n",
    "# Graficar los espectrogramas STFT para cada clase\n",
    "for class_name in stft_spectrograms.keys():\n",
    "    plot_stft_spectrograms(stft_spectrograms, class_name, sampling_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stft_spectrograms['auto'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PASAMOS LOS ESPECTOGRAMAS A TENSORES PARA ARMAR EL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'men' contiene 'tiempo' que queremos de los espectrogramas\n",
    "men = 220 # Ajusta la longitud esta en centisegunos creo... hay que revisar\n",
    "\n",
    "# Convertir los espectrogramas de Mel a tensores de PyTorch\n",
    "mel_tensor_list = []\n",
    "labels_list = []\n",
    "\n",
    "# Iterar sobre las clases y los espectrogramas de Mel correspondientes\n",
    "for label, mel_specs in stft_spectrograms.items():\n",
    "    for mel_spec in mel_specs:\n",
    "        # Asegurarse de que todos los espectrogramas tengan la misma forma (128, men)\n",
    "        if mel_spec.shape[1] > men:\n",
    "            mel_spec = mel_spec[:, :men]  # Recortar si es más largo\n",
    "        elif mel_spec.shape[1] < men:\n",
    "            mel_spec = np.pad(mel_spec, ((0, 0), (0, men - mel_spec.shape[1])), mode='constant')  # Rellenar si es más corto\n",
    "        \n",
    "        mel_tensor = torch.tensor(mel_spec).unsqueeze(0).float()  # Convertir y añadir dimensión de canal\n",
    "        mel_tensor_list.append(mel_tensor)\n",
    "        labels_list.append(label)\n",
    "\n",
    "# Convertir la lista de etiquetas a tensores de PyTorch\n",
    "labels_tensor = torch.tensor([list(stft_spectrograms.keys()).index(label) for label in labels_list])\n",
    "\n",
    "# Crear un Dataset de PyTorch\n",
    "dataset = TensorDataset(torch.stack(mel_tensor_list), labels_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar un espectrograma de Mel para graficar\n",
    "mel_spec_to_plot = mel_tensor_list[0].squeeze().numpy()  # Convertir de tensor a numpy y eliminar la dimensión del canal\n",
    "\n",
    "# Graficar el espectrograma de Mel\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(mel_spec_to_plot, cmap='viridis', origin='lower', aspect='auto')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Espectrograma de Mel Redimensionado')\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a un solo elemento del dataset (por ejemplo, el primer elemento)\n",
    "sample_image, sample_label = dataset[0]\n",
    "\n",
    "# Inspeccionar las dimensiones del tensor de la imagen\n",
    "print(\"Dimensiones de la imagen:\", sample_image.size())\n",
    "\n",
    "# Inspeccionar las dimensiones del tensor de etiquetas\n",
    "print(\"Dimensiones de la etiqueta:\", sample_label.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEPARAMOS EN TRAIN Y VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Definir el tamaño del conjunto de entrenamiento y validación\n",
    "train_size = int(0.8 * len(dataset))  # Usaremos el 80% para entrenamiento\n",
    "val_size = len(dataset) - train_size  # El restante para validación\n",
    "\n",
    "# Dividir el dataset en conjuntos de entrenamiento y validación\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Opcionalmente, puedes imprimir el tamaño de cada conjunto para verificar\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {len(train_dataset)}\")\n",
    "print(f\"Tamaño del conjunto de validación: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Definir el tamaño del lote (batch size)\n",
    "batch_size = 32  # Puedes ajustar este valor según la memoria disponible y el tamaño de tu dataset\n",
    "\n",
    "# Crear DataLoader para el conjunto de entrenamiento\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Crear DataLoader para el conjunto de validación\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una red neuronal convolucional simple\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Calcular el tamaño de entrada para la capa fully connected\n",
    "        input_size = self._get_conv_output_size((1, 1, 11026, 220))  # Ajustar según las nuevas dimensiones de entrada, ver tamaño de imagen\n",
    "        self.fc1 = nn.Linear(input_size, 128)  # Ajustar el tamaño de entrada según el tamaño de salida calculado\n",
    "        \n",
    "        self.lstm = nn.LSTM(128, 64, batch_first=True)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def _get_conv_output_size(self, shape):\n",
    "        # Crear un tensor de entrada con las dimensiones especificadas\n",
    "        x = torch.randn(shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        # Calcular el tamaño de salida después de aplanar\n",
    "        return x.view(x.size(0), -1).size(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        # Aplanar la salida de las capas convolucionales para la capa fully connected\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # Agregar la dimensión de tiempo para la entrada a la capa LSTM\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        x = lstm_out[:, -1, :]  # Tomar solo la última salida de la secuencia LSTM\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSTANCIAMOS EL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir hiperparámetros\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 50\n",
    "\n",
    "# Crear una instancia del modelo\n",
    "model = SimpleCNN(num_classes=4)  # Ajusta num_classes según el número de clases en tu dataset\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCION DE ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de entrenamiento\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Modo de entrenamiento\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Modo de evaluación\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_preds += (predicted == labels).sum().item()\n",
    "                total_preds += labels.size(0)\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        val_accuracy = correct_preds / total_preds\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Imprimir métricas del epoch\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
    "    \n",
    "    # Graficar las curvas de pérdida y precisión en validación\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(np.arange(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(np.arange(1, num_epochs + 1), val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(np.arange(1, num_epochs + 1), val_accuracies, label='Val Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Validation Accuracy over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
