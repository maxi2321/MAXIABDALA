<!DOCTYPE html>
<html lang="en" data-rh="lang"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><title>Speaker Differentiation Using Deep Learning | by Daniel Shapiro, PhD | Towards Data Science</title><meta data-rh="true" charset="utf-8"><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"><meta data-rh="true" name="theme-color" content="#000000"><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"><meta data-rh="true" property="al:ios:app_name" content="Medium"><meta data-rh="true" property="al:ios:app_store_id" content="828256236"><meta data-rh="true" property="al:android:package" content="com.medium.reader"><meta data-rh="true" property="fb:app_id" content="542599432471018"><meta data-rh="true" property="og:site_name" content="Medium"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2018-12-21T16:53:03.502Z"><meta data-rh="true" name="title" content="Speaker Differentiation Using Deep Learning | by Daniel Shapiro, PhD | Towards Data Science"><meta data-rh="true" property="og:title" content="Speaker Differentiation Using Deep Learning"><meta data-rh="true" property="al:android:url" content="medium://p/68b2dede498f"><meta data-rh="true" property="al:ios:url" content="medium://p/68b2dede498f"><meta data-rh="true" property="al:android:app_name" content="Medium"><meta data-rh="true" name="description" content="Last week, I presented a conference paper at ICSEE2018 on a neural network system with the ability to quickly differentiate between speakers in dual microphone audio. This is related to the cocktail…"><meta data-rh="true" property="og:description" content="Last week, I presented a conference paper at ICSEE2018 on a neural network system with the ability to quickly differentiate between…"><meta data-rh="true" property="og:url" content="https://towardsdatascience.com/speaker-differentiation-using-deep-learning-68b2dede498f"><meta data-rh="true" property="al:web:url" content="https://towardsdatascience.com/speaker-differentiation-using-deep-learning-68b2dede498f"><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/resize:fit:956/1*ojCq-1v1IRSGFq8-0Nflhg.png"><meta data-rh="true" property="article:author" content="https://medium.com/@lemaysolutions"><meta data-rh="true" name="author" content="Daniel Shapiro, PhD"><meta data-rh="true" name="robots" content="index,follow,max-image-preview:large"><meta data-rh="true" name="referrer" content="unsafe-url"><meta data-rh="true" property="twitter:title" content="Speaker Differentiation Using Deep Learning"><meta data-rh="true" name="twitter:site" content="@TDataScience"><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/68b2dede498f"><meta data-rh="true" property="twitter:description" content="Last week, I presented a conference paper at ICSEE2018 on a neural network system with the ability to quickly differentiate between…"><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/resize:fit:956/1*ojCq-1v1IRSGFq8-0Nflhg.png"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" name="twitter:creator" content="@Lemay_ai"><meta data-rh="true" name="twitter:label1" content="Reading time"><meta data-rh="true" name="twitter:data1" content="7 min read"><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://towardsdatascience.com/osd.xml"><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:152:152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:120:120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:76:76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:60:60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg" color="#171717"><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/unbound.css"><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/unbound.css"><link data-rh="true" rel="author" href="https://medium.com/@lemaysolutions"><link data-rh="true" rel="canonical" href="https://towardsdatascience.com/speaker-differentiation-using-deep-learning-68b2dede498f"><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/68b2dede498f"><script type="text/javascript" async="" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/recaptcha__en.js" crossorigin="anonymous" integrity="sha384-rT2oxg4iyBQHCBDmO5FKCpCkuhA/D4wr4iso9Mam8l5oD+twbrStu6rkUmnvVmtw"></script><script async="" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/branch-latest.min.js"></script><script async="" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/shim.js"></script><style type="text/css" data-fela-rehydration="484" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}.grecaptcha-badge{visibility:hidden}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="484" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-webkit-keyframes k2{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@-moz-keyframes k2{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@keyframes k2{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@-webkit-keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@-moz-keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}</style><style type="text/css" data-fela-rehydration="484" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:sticky}.n{top:0}.o{z-index:500}.p{padding:0 24px}.q{align-items:center}.r{border-bottom:solid 1px #F2F2F2}.y{height:41px}.z{line-height:20px}.ab{display:flex}.ac{height:57px}.ae{flex:1 0 auto}.af{color:inherit}.ag{fill:inherit}.ah{font-size:inherit}.ai{border:inherit}.aj{font-family:inherit}.ak{letter-spacing:inherit}.al{font-weight:inherit}.am{padding:0}.an{margin:0}.ao{cursor:pointer}.ap:disabled{cursor:not-allowed}.aq:disabled{color:#6B6B6B}.ar:disabled{fill:#6B6B6B}.au{fill:rgba(0, 0, 0, 1)}.av{height:22px}.aw{margin-left:16px}.ax{border:none}.ay{border-radius:20px}.az{width:240px}.ba{background:#F9F9F9}.bb path{fill:#6B6B6B}.bd{outline:none}.be{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bf{font-size:14px}.bg{width:100%}.bh{padding:10px 20px 10px 0}.bi{background-color:transparent}.bj{color:#242424}.bk::placeholder{color:#6B6B6B}.bl{display:inline-block}.bm{margin-left:12px}.bn{margin-right:12px}.bo{border-radius:4px}.bp{margin-left:24px}.bq{height:24px}.bw{background-color:#F9F9F9}.bx{border-radius:50%}.by{height:32px}.bz{width:32px}.ca{justify-content:center}.cg{max-width:680px}.ch{min-width:0}.ci{animation:k1 1.2s ease-in-out infinite}.cj{height:100vh}.ck{margin-bottom:16px}.cl{margin-top:48px}.cm{align-items:flex-start}.cn{flex-direction:column}.co{justify-content:space-between}.cp{margin-bottom:24px}.cv{width:80%}.cw{background-color:#F2F2F2}.dc{height:44px}.dd{width:44px}.de{margin:auto 0}.df{margin-bottom:4px}.dg{height:16px}.dh{width:120px}.di{width:80px}.do{margin-bottom:8px}.dp{width:96%}.dq{width:98%}.dr{width:81%}.dv{margin-left:8px}.dw{color:#6B6B6B}.dx{font-size:13px}.dy{height:100%}.dz{height:25px}.ea{fill:rgba(41, 41, 41, 1)}.ed{margin-right:32px}.ee{position:relative}.ef{fill:#6B6B6B}.ei{background:transparent}.ej svg{margin-left:4px}.ek svg{fill:#6B6B6B}.em{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.eo{position:absolute}.eq{box-sizing:border-box}.ew{margin:0 24px}.fa{background:rgba(255, 255, 255, 1)}.fb{border:1px solid #F2F2F2}.fc{box-shadow:0 1px 4px #F2F2F2}.fd{max-height:100vh}.fe{overflow-y:auto}.ff{left:0}.fg{top:calc(100vh + 100px)}.fh{bottom:calc(100vh + 100px)}.fi{width:10px}.fj{pointer-events:none}.fk{word-break:break-word}.fl{word-wrap:break-word}.fm:after{display:block}.fn:after{content:""}.fo:after{clear:both}.fp{margin-left:auto}.fq{margin-right:auto}.fr{max-width:956px}.fx{clear:both}.fz{cursor:zoom-in}.ga{z-index:auto}.gc{max-width:100%}.gd{height:auto}.ge{line-height:1.23}.gf{letter-spacing:0}.gg{font-style:normal}.gh{font-weight:700}.hh{@media all and (max-width: 551.98px):8px}.hi{@media all and (min-width: 552px) and (max-width: 727.98px):8px}.hj{@media all and (min-width: 728px) and (max-width: 903.98px):16px}.hk{@media all and (min-width: 904px) and (max-width: 1079.98px):16px}.hl{@media all and (min-width: 1080px):16px}.hr{align-items:baseline}.hs{width:48px}.ht{height:48px}.hu{border:2px solid rgba(255, 255, 255, 1)}.hv{z-index:0}.hw{box-shadow:none}.hx{border:1px solid rgba(0, 0, 0, 0.05)}.hy{margin-left:-12px}.hz{width:28px}.ia{height:28px}.ib{z-index:1}.ic{width:24px}.id{margin-bottom:2px}.ie{flex-wrap:nowrap}.if{font-size:16px}.ig{line-height:24px}.ii{margin:0 8px}.ij{display:inline}.ik{color:rgba(102, 138, 170, 1)}.il{fill:rgba(102, 138, 170, 1)}.im:disabled{opacity:0.3}.ip{flex:0 0 auto}.is{flex-wrap:wrap}.iv{white-space:pre-wrap}.iw{margin-right:4px}.ix{overflow:hidden}.iy{max-height:20px}.iz{text-overflow:ellipsis}.ja{display:-webkit-box}.jb{-webkit-line-clamp:1}.jc{-webkit-box-orient:vertical}.jd{word-break:break-all}.jf{padding-left:8px}.jg{padding-right:8px}.kh> *{flex-shrink:0}.ki{overflow-x:scroll}.kj::-webkit-scrollbar{display:none}.kk{scrollbar-width:none}.kl{-ms-overflow-style:none}.km{width:74px}.kn{flex-direction:row}.ko{z-index:2}.kr{-webkit-user-select:none}.ks{border:0}.kt{cursor:progress}.ku{fill:rgba(117, 117, 117, 1)}.kx{opacity:0.25}.ky{outline:0}.kz{user-select:none}.la> svg{pointer-events:none}.lj{margin-left:4px}.lk{margin-top:0px}.ll{opacity:1}.lm{padding:4px 0}.lp{width:16px}.lq{padding:8px 2px}.lt svg path{fill:#6B6B6B}.lu path{fill:#242424}.lv{display:inline-flex}.mb svg{color:#6B6B6B}.ms{line-height:1.58}.mt{letter-spacing:-0.004em}.mu{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.np{margin-bottom:-0.46em}.nq{clear:left}.nr{float:left}.ns{font-size:66px}.nt{line-height:.83}.nz{text-decoration:underline}.oa{max-width:593px}.og{margin-top:10px}.oh{text-align:center}.oi{max-width:728px}.ol{background:none}.om{text-decoration:none}.on{max-width:347px}.oo{max-width:573px}.op{max-width:449px}.oq{max-width:635px}.or{max-width:640px}.os{list-style-type:disc}.ot{margin-left:30px}.ou{padding-left:0px}.pa{margin-bottom:26px}.pb{margin-top:6px}.pc{margin-top:8px}.pd{margin-right:8px}.pe{padding:8px 16px}.pf{border-radius:100px}.pg{transition:background 300ms ease}.pi{white-space:nowrap}.pj{border-top:none}.pp{height:52px}.pq{max-height:52px}.pr{box-sizing:content-box}.ps{position:static}.pu{max-width:155px}.qa{margin-right:20px}.qg{align-items:flex-end}.qh{width:76px}.qi{height:76px}.qj{border:2px solid #F9F9F9}.qk{height:72px}.ql{width:72px}.qm{margin-left:-16px}.qn{width:36px}.qo{height:36px}.qp{color:#F2F2F2}.qq{fill:#F2F2F2}.qr{background:#F2F2F2}.qs{border-color:#F2F2F2}.qy:disabled{cursor:inherit !important}.qz:disabled:hover{background:rgba(102, 138, 170, 1)}.ra:disabled:hover{border-color:rgba(102, 138, 170, 1)}.rb{border-radius:99em}.rc{width:auto}.rd{border-width:1px}.re{border-style:solid}.rf{stroke:#F2F2F2}.rg{font-weight:500}.rh{font-size:24px}.ri{line-height:30px}.rj{letter-spacing:-0.016em}.rk{margin-top:16px}.rl{height:0px}.rm{border-bottom:solid 1px #E5E5E5}.rn{margin-top:72px}.ro{padding:24px 0}.rp{margin-bottom:0px}.rq{margin-right:16px}.as:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.at:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.eg:hover{color:#242424}.eh:hover{fill:#242424}.el:hover svg{fill:#242424}.ep:hover{background-color:rgba(0, 0, 0, 0.1)}.ih:hover{text-decoration:underline}.in:hover:not(:disabled){color:rgba(90, 118, 144, 1)}.io:hover:not(:disabled){fill:rgba(90, 118, 144, 1)}.kw:hover{fill:rgba(117, 117, 117, 1)}.ln:hover{fill:#000000}.lo:hover p{color:#000000}.lr:hover:not(:disabled) svg path{fill:#000000}.mc:hover svg{color:#000000}.ph:hover{background-color:#F2F2F2}.qt:hover{background:#F2F2F2}.qu:hover{border-color:#F2F2F2}.qv:hover{cursor:wait}.qw:hover{color:#F2F2F2}.qx:hover{fill:#F2F2F2}.bc:focus-within path{fill:#242424}.gb:focus{transform:scale(1.01)}.kv:focus{fill:rgba(117, 117, 117, 1)}.ls:focus svg path{fill:#000000}.md:focus svg{color:#000000}.lb:active{border-style:none}</style><style type="text/css" data-fela-rehydration="484" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.bv{width:64px}.cf{margin:0 64px}.cu{height:48px}.db{margin-bottom:52px}.dn{margin-bottom:48px}.ec{display:flex}.ev{margin-bottom:68px}.ez{max-width:680px}.fw{margin-top:40px}.hc{font-size:42px}.hd{margin-top:1em}.he{margin-bottom:32px}.hf{line-height:52px}.hg{letter-spacing:-0.011em}.hq{align-items:center}.jt{border-top:solid 1px #F2F2F2}.ju{border-bottom:solid 1px #F2F2F2}.jv{margin:32px 0 0}.jw{padding:3px 8px}.kf> *{margin-right:24px}.kg> :last-child{margin-right:0}.li{margin-top:0px}.ma{margin:0}.nl{font-size:20px}.nm{margin-top:2.14em}.nn{line-height:32px}.no{letter-spacing:-0.003em}.ny{padding-top:7px}.of{margin-top:56px}.oz{margin-top:1.14em}.po{margin-bottom:88px}.pz{display:inline-block}.qf{padding-top:72px}</style><style type="text/css" data-fela-rehydration="484" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.lh{margin-top:0px}.oj{margin-left:auto}.ok{text-align:center}.py{display:inline-block}</style><style type="text/css" data-fela-rehydration="484" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.lg{margin-top:0px}.px{display:inline-block}</style><style type="text/css" data-fela-rehydration="484" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.le{margin-top:0px}.lf{margin-right:0px}.pw{display:inline-block}</style><style type="text/css" data-fela-rehydration="484" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.s{display:flex}.t{justify-content:space-between}.br{width:24px}.cb{margin:0 24px}.cq{height:40px}.cx{margin-bottom:44px}.dj{margin-bottom:32px}.ds{justify-content:center}.er{margin-bottom:4px}.fs{margin-top:32px}.gi{font-size:32px}.gj{margin-top:1.01em}.gk{margin-bottom:24px}.gl{line-height:38px}.gm{letter-spacing:-0.014em}.hm{align-items:flex-start}.iq{flex-direction:column}.it{margin-bottom:2px}.jh{margin:24px -24px 0}.ji{padding:0}.jx> *{margin-right:8px}.jy> :last-child{margin-right:24px}.kp{margin-left:0px}.lc{margin-top:0px}.ld{margin-right:0px}.lw{margin:0}.me{border:1px solid #F2F2F2}.mf{border-radius:99em}.mg{padding:0px 16px 0px 12px}.mh{height:38px}.mi{align-items:center}.mk svg{margin-right:8px}.mv{font-size:18px}.mw{margin-top:1.56em}.mx{line-height:28px}.my{letter-spacing:-0.003em}.nu{padding-top:0}.ob{margin-top:40px}.ov{margin-top:1.34em}.pk{margin-bottom:80px}.pv{display:inline-block}.qb{padding-top:48px}.mj:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="484" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.bu{width:64px}.ce{margin:0 64px}.ct{height:48px}.da{margin-bottom:52px}.dm{margin-bottom:48px}.eb{display:flex}.eu{margin-bottom:68px}.ey{max-width:680px}.fv{margin-top:40px}.gx{font-size:42px}.gy{margin-top:1em}.gz{margin-bottom:32px}.ha{line-height:52px}.hb{letter-spacing:-0.011em}.hp{align-items:center}.jp{border-top:solid 1px #F2F2F2}.jq{border-bottom:solid 1px #F2F2F2}.jr{margin:32px 0 0}.js{padding:3px 8px}.kd> *{margin-right:24px}.ke> :last-child{margin-right:0}.lz{margin:0}.nh{font-size:20px}.ni{margin-top:2.14em}.nj{line-height:32px}.nk{letter-spacing:-0.003em}.nx{padding-top:7px}.oe{margin-top:56px}.oy{margin-top:1.14em}.pn{margin-bottom:88px}.qe{padding-top:72px}</style><style type="text/css" data-fela-rehydration="484" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.w{display:flex}.x{justify-content:space-between}.bt{width:64px}.cd{margin:0 48px}.cs{height:48px}.cz{margin-bottom:52px}.dl{margin-bottom:48px}.du{justify-content:center}.et{margin-bottom:68px}.ex{max-width:680px}.fu{margin-top:40px}.gs{font-size:42px}.gt{margin-top:1em}.gu{margin-bottom:32px}.gv{line-height:52px}.gw{letter-spacing:-0.011em}.ho{align-items:center}.jl{border-top:solid 1px #F2F2F2}.jm{border-bottom:solid 1px #F2F2F2}.jn{margin:32px 0 0}.jo{padding:3px 8px}.kb> *{margin-right:24px}.kc> :last-child{margin-right:0}.ly{margin:0}.nd{font-size:20px}.ne{margin-top:2.14em}.nf{line-height:32px}.ng{letter-spacing:-0.003em}.nw{padding-top:7px}.od{margin-top:56px}.ox{margin-top:1.14em}.pm{margin-bottom:88px}.qd{padding-top:72px}</style><style type="text/css" data-fela-rehydration="484" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.u{display:flex}.v{justify-content:space-between}.bs{width:24px}.cc{margin:0 24px}.cr{height:40px}.cy{margin-bottom:44px}.dk{margin-bottom:32px}.dt{justify-content:center}.es{margin-bottom:4px}.ft{margin-top:32px}.gn{font-size:32px}.go{margin-top:1.01em}.gp{margin-bottom:24px}.gq{line-height:38px}.gr{letter-spacing:-0.014em}.hn{align-items:flex-start}.ir{flex-direction:column}.iu{margin-bottom:2px}.jj{margin:24px 0 0}.jk{padding:0}.jz> *{margin-right:8px}.ka> :last-child{margin-right:8px}.kq{margin-left:0px}.lx{margin:0}.ml{border:1px solid #F2F2F2}.mm{border-radius:99em}.mn{padding:0px 16px 0px 12px}.mo{height:38px}.mp{align-items:center}.mr svg{margin-right:8px}.mz{font-size:18px}.na{margin-top:1.56em}.nb{line-height:28px}.nc{letter-spacing:-0.003em}.nv{padding-top:0}.oc{margin-top:40px}.ow{margin-top:1.34em}.pl{margin-bottom:80px}.qc{padding-top:48px}.mq:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="484" data-fela-type="RULE" media="print">.pt{display:none}</style><style type="text/css" data-fela-rehydration="484" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.fy{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style><style type="text/css" data-fela-rehydration="484" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.je{max-height:none}</style><link rel="icon" href="https://miro.medium.com/v2/resize:fill:128:128/1*VzTUkfeGymHP4Bvav-T-lA.png" data-rh="true"><script type="application/ld+json" data-rh="true">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:1200\u002F1*ojCq-1v1IRSGFq8-0Nflhg.png"],"url":"https:\u002F\u002Ftowardsdatascience.com\u002Fspeaker-differentiation-using-deep-learning-68b2dede498f","dateCreated":"2018-12-21T16:53:03.502Z","datePublished":"2018-12-21T16:53:03.502Z","dateModified":"2021-12-07T02:04:55.463Z","headline":"Speaker Differentiation Using Deep Learning - Towards Data Science","name":"Speaker Differentiation Using Deep Learning - Towards Data Science","description":"Last week, I presented a conference paper at ICSEE2018 on a neural network system with the ability to quickly differentiate between speakers in dual microphone audio. This is related to the cocktail…","identifier":"68b2dede498f","author":{"@type":"Person","name":"Daniel Shapiro, PhD","url":"https:\u002F\u002Ftowardsdatascience.com\u002F@lemaysolutions"},"creator":["Daniel Shapiro, PhD"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"towardsdatascience.com","logo":{"@type":"ImageObject","width":192,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:192\u002F1*cFFKn8rFH4ZndmaYeAs6iQ.png"}},"mainEntityOfPage":"https:\u002F\u002Ftowardsdatascience.com\u002Fspeaker-differentiation-using-deep-learning-68b2dede498f"}</script><script async="true" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/js" data-rh="true"></script><script data-rh="true">window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-7JY7T788PK');</script><script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/enterprise.js" data-rh="true"></script><script type="text/javascript" data-rh="true">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent".split(" "), 0);
branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {metadata: {}, 'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled': null}, function(err, data) {});</script></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div><script>if (window.self !== window.top) window.location = "about:blank"</script></div><div class="l c"><div class="l m n o c" style="transform: translateY(-57px);"><div class="am q r s ds u dt w du i d y z"><a class="dw ag dx be ak b am an ao ap aq ar as at s u w i d q dy z" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F68b2dede498f&amp;%7Efeature=LiOpenInAppButton&amp;%7Echannel=ShowPostUnderCollection&amp;source=---two_column_layout_nav----------------------------------" rel="noopener follow">Open in app<svg width="10" height="10" viewBox="0 0 10 10" fill="none" class="dv"><path d="M.98 8.48a.37.37 0 1 0 .54.54l-.54-.54zm7.77-7.23h.38c0-.2-.17-.38-.38-.38v.38zM8.37 6.5a.37.37 0 1 0 .76 0h-.76zM3.5.87a.37.37 0 1 0 0 .76V.88zM1.52 9.03l7.5-7.5-.54-.54-7.5 7.5.54.54zm6.86-7.77V6.5h.74V1.25h-.74zm-4.88.38h5.25V.88H3.5v.74z" fill="currentColor"></path></svg></a></div><div class="p q r ab ac"><div class="ab q ae"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab" aria-label="Homepage" data-testid="headerMediumLogo" href="https://medium.com/?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><svg viewBox="0 0 1043.63 592.71" class="dz ea"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a><div class="aw h"><div class="ab ax ay az ba q bb bc"><div class="bl" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><div class="bm bn ab"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" data-testid="headerSearchInput" tabindex="0" class="ax bd be bf z bg bh bi bj bk" placeholder="Search"></div></div></div><div class="h k w eb ec"><div class="ed ab"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerWriteButton" href="https://medium.com/new-story?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><div class="be b bf z dw ee ef ab q eg eh"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Write"><path d="M14 4a.5.5 0 0 0 0-1v1zm7 6a.5.5 0 0 0-1 0h1zm-7-7H4v1h10V3zM3 4v16h1V4H3zm1 17h16v-1H4v1zm17-1V10h-1v10h1zm-1 1a1 1 0 0 0 1-1h-1v1zM3 20a1 1 0 0 0 1 1v-1H3zM4 3a1 1 0 0 0-1 1h1V3z" fill="currentColor"></path><path d="M17.5 4.5l-8.46 8.46a.25.25 0 0 0-.06.1l-.82 2.47c-.07.2.12.38.31.31l2.47-.82a.25.25 0 0 0 .1-.06L19.5 6.5m-2-2l2.32-2.32c.1-.1.26-.1.36 0l1.64 1.64c.1.1.1.26 0 .36L19.5 6.5m-2-2l2 2" stroke="currentColor"></path></svg><div class="dv l">Write</div></div></a></div></div><div class="k j i d"><div class="ed ab"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSearchButton" href="https://medium.com/search?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><div class="be b bf z dw ee ef ab q eg eh"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Search"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div></a></div></div><div class="ed ab"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerNotificationButton" href="https://medium.com/me/notifications?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><div class="be b bf z dw ee ef ab q eg eh"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Notifications"><path d="M15 18.5a3 3 0 1 1-6 0" stroke="currentColor" stroke-linecap="round"></path><path d="M5.5 10.53V9a6.5 6.5 0 0 1 13 0v1.53c0 1.42.56 2.78 1.57 3.79l.03.03c.26.26.4.6.4.97v2.93c0 .14-.11.25-.25.25H3.75a.25.25 0 0 1-.25-.25v-2.93c0-.37.14-.71.4-.97l.03-.03c1-1 1.57-2.37 1.57-3.79z" stroke="currentColor" stroke-linejoin="round"></path></svg><div class="be b ub uc ud eo ue uf ug uh ui uj oh bl uk ul" data-testid="headerNotificationCount">1</div></div></a></div><div class="l" aria-hidden="false"><button class="ax ei am ab q ao ej ek el" aria-label="user options menu" data-testid="headerUserIcon"><div class="l ee"><div class="l ee"><img alt="Sebastián López" class="l eq bx by bz cw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%20pLvuvXRh9wIbC5a8.jpg" width="32" height="32" loading="lazy"><div class="em bx l by bz eo n ax ep"></div></div></div></button></div></div></div><div class="l"><div class="bw"><div class="ji hm t jk hn v ry ho du rz hp sa sb hq sc ab ee"><div class="sd hm se hn ho hp hq ab ee"><div class="sf sg sh si sj sk sl ab"><svg width="64" height="64" viewBox="0 0 64 64" fill="none" role="presentation" aria-hidden="true" focusable="false" class="sm sn"><path d="M39.64 40.83L33.87 56.7a1.99 1.99 0 0 1-3.74 0l-5.77-15.87a2.02 2.02 0 0 0-1.2-1.2L7.3 33.88a1.99 1.99 0 0 1 0-3.74l15.87-5.77a2.02 2.02 0 0 0 1.2-1.2L30.12 7.3a1.99 1.99 0 0 1 3.74 0l5.77 15.87a2.02 2.02 0 0 0 1.2 1.2l15.86 5.76a1.99 1.99 0 0 1 0 3.74l-15.87 5.77a2.02 2.02 0 0 0-1.2 1.2z" fill="#FFC017"></path></svg></div><p class="be b bf z bj"><span class="pd ij">Get unlimited access to the best of Medium for less than $1/week.</span><div class="bl"><a class="af ag ah ai aj ak al am an ao ap aq ar nz bl" href="https://medium.com/plans?source=upgrade_membership---post_top_nav_upsell----------------------------------" rel="noopener follow"><div class="j i d"><span class="rg so fn sp sq sr ss">Become a member</span></div><div class="h k"><span class="rg">Become a member</span></div></a></div></p></div><div class="st su sv sw sx l sy"><div class="h k"><div class="l ee n sz"><button class="af ag ah ai aj ak al am an ao ap aq ar as at ab" data-testid="close-button" aria-label="close"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="ef dw eh eg"><path d="M5 5l7 7m7 7l-7-7m0 0l7-7m-7 7l-7 7" stroke="currentColor" stroke-linecap="round"></path></svg></button></div></div><div class="j i d"><div class="l ee n sz"><button class="af ag ah ai aj ak al am an ao ap aq ar as at ab ee so fn ta tb tc td" data-testid="close-button" aria-label="close"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="ef dw eh eg"><path d="M5 5l7 7m7 7l-7-7m0 0l7-7m-7 7l-7 7" stroke="currentColor" stroke-linecap="round"></path></svg></button></div></div></div></div></div><div class="pt" role="dialog" aria-modal="true" tabindex="-1"><div class="te tf bg dy tg th ti ao tj fj tk" aria-hidden="true" role="presentation"></div><div class="tl tg tm tn to te dy eq tp tq tr ll ts tt tu tv tw tx ty tz ua" aria-hidden="true"></div></div><div class="er es et eu ev l"><div class="ab ca"><div class="ch bg ew ex ey ez"></div></div><article><div class="l"><div class="l"><span class="l"></span><section><div><div class="eo ff fg fh fi fj"></div><div class="fk fl fm fn fo"><div class="ab ca"><div class="ch bg ew ex ey ez"><figure class="fs ft fu fv fw fx fp fq paragraph-image"><div role="button" tabindex="0" class="fy fz ee ga bg gb"><div class="fp fq fr"><picture><source srcset="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520ojCq-1v1IRSGFq8-0Nflhg_005.webp 640w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20ojCq-1v1IRSGFq8-0Nflhg.webp 720w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520ojCq-1v1IRSGFq8-0Nflhg_006.webp 750w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520ojCq-1v1IRSGFq8-0Nflhg_007.webp 786w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520ojCq-1v1IRSGFq8-0Nflhg_004.webp 828w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520ojCq-1v1IRSGFq8-0Nflhg_003.webp 1100w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520ojCq-1v1IRSGFq8-0Nflhg_002.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520ojCq-1v1IRSGFq8-0Nflhg_003.jpg 640w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520ojCq-1v1IRSGFq8-0Nflhg_006.jpg 720w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520ojCq-1v1IRSGFq8-0Nflhg_005.jpg 750w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520ojCq-1v1IRSGFq8-0Nflhg_007.jpg 786w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520ojCq-1v1IRSGFq8-0Nflhg_002.jpg 828w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520ojCq-1v1IRSGFq8-0Nflhg_004.jpg 1100w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520ojCq-1v1IRSGFq8-0Nflhg_008.jpg 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg gc gd c" width="700" height="201" loading="eager" role="presentation" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20ojCq-1v1IRSGFq8-0Nflhg.jpg"></picture></div></div></figure><div><h1 id="1246" class="pw-post-title ge gf gg be gh gi gj gk gl gm gn go gp gq gr gs gt gu gv gw gx gy gz ha hb hc hd he hf hg bj" data-testid="storyTitle" data-selectable-paragraph="">Speaker Differentiation Using Deep Learning</h1><div class="hh hi hj hk hl"><div class="speechify-ignore ab co"><div class="speechify-ignore bg l"><div class="hm hn ho hp hq ab"><div><div class="ab hr"><a href="https://medium.com/@lemaysolutions?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><div><div class="bl" aria-hidden="false" aria-describedby="1" aria-labelledby="1"><div class="l hs ht bx hu hv"><div class="l ee"><img alt="Daniel Shapiro, PhD" class="l eq bx dc dd cw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520moqpKxEKi4uSXIhNBwgOkQ_002.jpg" width="44" height="44" loading="lazy" data-testid="authorPhoto"><div class="hw bx l dc dd eo n hx ep"></div></div></div></div></div></a><a href="https://towardsdatascience.com/?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><div class="hy ab ee"><div><div class="bl" aria-hidden="false" aria-describedby="2" aria-labelledby="2"><div class="l hz ia bx hu ib"><div class="l ee"><img alt="Towards Data Science" class="l eq bx bq ic cw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20CJe3891yB1A1mzMdqemkdg.jpg" width="24" height="24" loading="lazy" data-testid="publicationPhoto"><div class="hw bx l bq ic eo n hx ep"></div></div></div></div></div></div></a></div></div><div class="bm bg l"><div class="ab"><div style="flex:1"><span class="be b bf z bj"><div class="id ab q"><div class="ab q ie"><div class="ab q"><div><div class="bl" aria-hidden="false" aria-describedby="3" aria-labelledby="3"><p class="be b if ig bj"><a class="af ag ah ai aj ak al am an ao ap aq ar ih" data-testid="authorName" href="https://medium.com/@lemaysolutions?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow">Daniel Shapiro, PhD</a></p></div></div></div><span class="ii ij" aria-hidden="true"><span class="be b bf z dw">·</span></span><p class="be b if ig dw"><button class="ik il ah ai aj ak al am an ao ap aq ar im in io">Follow</button></p></div></div></span></div></div><div class="l ip"><span class="be b bf z dw"><div class="ab cm iq ir is"><div class="it iu ab"><div class="be b bf z dw ab iv"><span class="iw l ip">Published in</span><div><div class="l" aria-hidden="false" aria-describedby="4" aria-labelledby="4"><a class="af ag ah ai aj ak al am an ao ap aq ar ih ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><p class="be b bf z ix iy iz ja jb jc jd je bj">Towards Data Science</p></a></div></div></div><div class="h k"><span class="ii ij" aria-hidden="true"><span class="be b bf z dw">·</span></span></div></div><span class="be b bf z dw"><div class="ab ae"><span data-testid="storyReadTime">7 min read</span><div class="jf jg l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="be b bf z dw">·</span></span></div><span data-testid="storyPublishDate">Dec 21, 2018</span></div></span></div></span></div></div></div><div class="ab co jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw"><div class="h k w eb ec q"><div class="km l"><div class="ab q kn ko"><div class="pw-multi-vote-icon ee iw kp kq kr"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="75" aria-labelledby="75"><button class="ks ao ku ut uu ky am kz la lb kr" data-testid="headerClapButton"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></button></div></div></div></div><div class="pw-multi-vote-count l lc ld le lf lg lh li"><div><div class="bl" aria-hidden="false" aria-describedby="76" aria-labelledby="76"><p class="be b dx z dw"><button class="af ag ah ai aj ak al am an ao ap aq ar as at uv uw">291<span class="l h g f py pz"></span></button></p></div></div></div></div></div><div><div class="bl" aria-hidden="false" aria-describedby="5" aria-labelledby="5"><button class="ao ks ll lm ab q ef ln lo" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" class="lk"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b dx z dw"><span class="pw-responses-count lj lk">1</span></p></button></div></div></div><div class="ab q jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl"><div class="lp k j i d"></div><div class="h k"><div><div class="bl" aria-hidden="false" aria-describedby="6" aria-labelledby="6"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="headerBookmarkButton" class="af ef ah ai aj ak al lq an ao ap im lr ls lt"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lu"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="eq lv cm"><div class="l ae"><div class="ab ca"><div class="lw lx ly lz ma gc ch bg"><div class="ab"><div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/plans?dimension=post_audio_button&amp;postId=68b2dede498f&amp;source=upgrade_membership---post_audio_button----------------------------------" rel="noopener follow"><div><div class="bl" aria-hidden="false" aria-describedby="24" aria-labelledby="24"><button aria-label="Listen" data-testid="audioPlayButton" class="af ef ah ai aj ak al lq an ao ap im mb mc lo md me mf mg mh s mi mj mk ml mm mn mo u mp mq mr"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0zm9-10a10 10 0 1 0 0 20 10 10 0 0 0 0-20zm3.38 10.42l-4.6 3.06a.5.5 0 0 1-.78-.41V8.93c0-.4.45-.63.78-.41l4.6 3.06c.3.2.3.64 0 .84z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z dw">Listen</p></div></button></div></div></a></div></div></div></div></div></div><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false" aria-describedby="8" aria-labelledby="8"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af ef ah ai aj ak al lq an ao ap im mb mc lo md me mf mg mh s mi mj mk ml mm mn mo u mp mq mr"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z dw">Share</p></div></button></div></div></div><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="81" aria-labelledby="81"><button aria-label="More options" data-testid="headerStoryOptionsButton" class="af ef ah ai aj ak al lq an ao ap im mb mc lo md me mf mg mh s mi mj mk ml mm mn mo u mp mq mr"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z dw">More</p></div></button></div></div></div></div></div></div></div></div></div></div><p id="2c88" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj nq" data-selectable-paragraph=""><span class="l nr ns nt bn nu nv nw nx ny ee">L</span>ast week, I presented a conference <a class="af nz" href="https://www.ieee.org.il/icsee-2018/" rel="noopener ugc nofollow" target="_blank">paper at ICSEE2018</a>
 on a neural network system with the ability to quickly differentiate 
between speakers in dual microphone audio. This is related to the <a class="af nz" href="https://www.youtube.com/watch?v=Qj5ltrAFric" rel="noopener ugc nofollow" target="_blank">cocktail party problem</a>.
 In my work, the idea is that a neural network learns how to separate 
voices into bins using a small amount of clean training data for each 
speaker (a very optimistic assumption). A further simplifying assumption
 is that there is normal background noise, but not something difficult 
like background music or loud noises. The hard part here, or depending 
on your point of view, the easy part, is that there should be minimal 
preprocessing. The neural network makes predictions on each segment of 
the audio, and when each of the voice signatures are detected in a given
 conversation, the speaker is recognized.</p><p id="fd05" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">In
 the more general cocktail party problem with multiple speakers, which 
is much harder, the idea is that these speakers can be recognised 
because we know who is talking by where they are and how loud they talk.
 In that scenario, the location of the speakers is relevant, whereas in 
our work the relative position of people talking to the microphones 
similar, and so we are focusing in on the speaker’s voice, rather than 
the voice power or relative location.</p><figure class="ob oc od oe of fx fp fq paragraph-image"><div class="fp fq oa"><picture><source srcset="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20x1CCK7bAT9XUEHzLhVc_gQ.webp 640w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520x1CCK7bAT9XUEHzLhVc_gQ_006.webp 720w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520x1CCK7bAT9XUEHzLhVc_gQ_004.webp 750w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520x1CCK7bAT9XUEHzLhVc_gQ_003.webp 786w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520x1CCK7bAT9XUEHzLhVc_gQ_005.webp 828w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520x1CCK7bAT9XUEHzLhVc_gQ_002.webp 1100w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520x1CCK7bAT9XUEHzLhVc_gQ_007.webp 1186w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 593px" type="image/webp"><source data-testid="og" srcset="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520x1CCK7bAT9XUEHzLhVc_gQ_008.png 640w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520x1CCK7bAT9XUEHzLhVc_gQ_006.png 720w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520x1CCK7bAT9XUEHzLhVc_gQ_004.png 750w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20x1CCK7bAT9XUEHzLhVc_gQ.png 786w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520x1CCK7bAT9XUEHzLhVc_gQ_005.png 828w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520x1CCK7bAT9XUEHzLhVc_gQ_003.png 1100w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520x1CCK7bAT9XUEHzLhVc_gQ_002.png 1186w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 593px"><img alt="" class="bg gc gd c" width="593" height="338" loading="lazy" role="presentation" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520x1CCK7bAT9XUEHzLhVc_gQ_007.png"></picture></div><figcaption class="og oh oi fp fq oj ok be b bf z dw" data-selectable-paragraph="">We used 2 microphones to record human voices.</figcaption></figure><p id="3e62" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">There
 is other work in this field on extracting features from single and dual
 microphone signals, and let’s skip over all of that. Our goal was to 
see if a certain kind of neural network could do the job with only basic
 preprocessing.</p><p id="1d5e" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">My coauthors <a class="af nz" href="https://ca.linkedin.com/in/mohamed-asni" rel="noopener ugc nofollow" target="_blank">Mohamed Asni</a>, Tony Mathew, <a class="af nz" href="http://www.site.uottawa.ca/~mbolic/" rel="noopener ugc nofollow" target="_blank">Dr. Miodrag Bolic</a>, and <div class="bl rc"><div><div class="bl" aria-hidden="false" aria-describedby="52" aria-labelledby="52"><a class="ol ik om" href="https://medium.com/u/136fa39ffeba?source=post_page-----68b2dede498f--------------------------------" rel="noopener" target="_blank">Leor Grebler</a></div></div></div>
 worked with me on this paper for a really long time. I feel like it 
took us about a year. Counting back to the grant and the idea stages, 
more than a year. The project stretched on from requirements gathering 
to solution architecture, and then data collection, and finally the 
development, analysis, drafting, submission of the paper, and 
presentation at the conference. These things happen slowly. The paper 
should show up in <a class="af nz" href="https://ieeexplore.ieee.org/" rel="noopener ugc nofollow" target="_blank">IEEE Xplore</a> and <a class="af nz" href="https://scholar.google.ca/" rel="noopener ugc nofollow" target="_blank">Google Scholar</a> before you know it.</p><p id="2958" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">At
 the end of the day, we developed a deep learning solution for 
differentiating human voices in audio originating from two microphone 
sources simultaneously. To understand the solution better, let’s briefly
 talk about autoencoders, convolution, MFCC, and more. I’m not going to 
cover everything we did in the paper, or present the prior art. Instead I
 want to give you an idea of what we did from a solution architecture 
perspective.</p><p id="b1d3" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">An <a class="af nz" href="https://en.wikipedia.org/wiki/Autoencoder" rel="noopener ugc nofollow" target="_blank">Autoencoder</a>
 (AE) reduces the dimensions of an input to a latent space 
representation (the encoder part of an AE) and then attempts to 
reconstruct the compressed data (the decoder). This encoder-decoder 
system is meant to compress the input into some lower dimensional latent
 space that preserves the essential information of the input. Put 
another way, it can be seen as an automated feature extractor. <a class="af nz" href="https://link.springer.com/chapter/10.1007%2F978-3-642-21735-7_7" rel="noopener ugc nofollow" target="_blank">Convolutional AEs, (CAEs)</a> are based on AEs where <a class="af nz" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">convolutional layers</a> are used for encoding/decoding, rather than <a class="af nz" href="https://en.wikipedia.org/wiki/Multilayer_perceptron" rel="noopener ugc nofollow" target="_blank">layers in an MLP</a>.</p><p id="a593" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">So,
 we used CAE for automatic feature extraction and generation of accurate
 latent space representations, but we didn’t do that on raw audio. <a class="af nz" href="https://en.wikipedia.org/wiki/Mel-frequency_cepstrum" rel="noopener ugc nofollow" target="_blank">Mel-frequency cepstrum</a>
 (MFCC) provides a short-term spectral representation of audio features.
 MFCC is a compact form of the amplitude spectrum representation of 
audio. It reduces computational cost when used as a preprocessing step 
for feature extraction, and it is widely known and used for human speech
 stuff. And so, as shown in the image below, we preprocessed that raw 
audio into MFCC before classifying it using a CAE.</p><figure class="ob oc od oe of fx fp fq paragraph-image"><div class="fp fq on"><picture><source srcset="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%207e0g4xr9yahoCGjp.webp 640w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%25207e0g4xr9yahoCGjp_006.webp 720w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%25207e0g4xr9yahoCGjp_003.webp 750w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%25207e0g4xr9yahoCGjp_005.webp 786w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%25207e0g4xr9yahoCGjp_007.webp 828w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%25207e0g4xr9yahoCGjp_002.webp 1100w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%25207e0g4xr9yahoCGjp_004.webp 694w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 347px" type="image/webp"><source data-testid="og" srcset="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%25207e0g4xr9yahoCGjp_005.png 640w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%25207e0g4xr9yahoCGjp_008.png 720w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%207e0g4xr9yahoCGjp.png 750w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%25207e0g4xr9yahoCGjp_002.png 786w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%25207e0g4xr9yahoCGjp_003.png 828w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%25207e0g4xr9yahoCGjp_004.png 1100w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%25207e0g4xr9yahoCGjp_007.png 694w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 347px"><img alt="" class="bg gc gd c" width="347" height="275" loading="lazy" role="presentation" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%25207e0g4xr9yahoCGjp_006.png"></picture></div><figcaption class="og oh oi fp fq oj ok be b bf z dw" data-selectable-paragraph="">Single microphone audio preprocessing leading to the AI model’s input</figcaption></figure><p id="5010" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">The
 basic aim of this work was to evaluate the CAE’s accuracy as the number
 of buckets at the network’s output increases. We wanted to do this 
without heavy preprocessing, using input from two microphone sources 
simultaneously. Our expectation going into this project was that no 
matter the size and quality of the dataset, as the number of speakers 
(buckets) increases, the model’s accuracy would eventually decrease. We 
expected this because the problem gets harder as more possibilities for 
the output labels are possible. The intuition is that with 2 speakers 
you have a 50% chance of guessing right by chance, but with 10 speakers 
you have only a 10% chance. And so separating out who is talking is 
harder when it could be one of many people.</p><p id="a64c" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">The following <a class="af nz" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py" rel="noopener ugc nofollow" target="_blank">confusion matrix</a>
 shows the dual microphone result for differentiating between 3 
speakers. The system recognised 2 of the 3 speakers 12 tries out of 12, 
but the third speaker was confused twice for the first speaker and once 
for the second speaker.</p><figure class="ob oc od oe of fx fp fq paragraph-image"><div class="fp fq oo"><picture><source srcset="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%20wsNeS6xhesiF3nnY.webp 640w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520wsNeS6xhesiF3nnY_006.webp 720w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520wsNeS6xhesiF3nnY_007.webp 750w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520wsNeS6xhesiF3nnY_004.webp 786w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520wsNeS6xhesiF3nnY_002.webp 828w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520wsNeS6xhesiF3nnY_003.webp 1100w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520wsNeS6xhesiF3nnY_005.webp 1146w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 573px" type="image/webp"><source data-testid="og" srcset="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520wsNeS6xhesiF3nnY_004.png 640w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%20wsNeS6xhesiF3nnY.png 720w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520wsNeS6xhesiF3nnY_008.png 750w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520wsNeS6xhesiF3nnY_006.png 786w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520wsNeS6xhesiF3nnY_003.png 828w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520wsNeS6xhesiF3nnY_002.png 1100w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520wsNeS6xhesiF3nnY_007.png 1146w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 573px"><img alt="" class="bg gc gd c" width="573" height="443" loading="lazy" role="presentation" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520wsNeS6xhesiF3nnY_005.png"></picture></div><figcaption class="og oh oi fp fq oj ok be b bf z dw" data-selectable-paragraph="">Confusion matrix for 3 speakers in a dual microphone setup</figcaption></figure><p id="2620" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">Let’s
 talk a bit more about how the above experiment was performed, and how 
the CAE was designed. The data was collected using two microphones 
simultaneously, and saved into separate WAV files. We had to collect our
 own data, as dual microphone datasets are hard to find. We copied the 
phrases of a common voice dataset, effectively extending it into the 
dual microphone domain for our narrow application and small dataset. We 
recorded with a sampling rate of 44100 Hz, with each audio snippet 
consisting of a 10 second duration. There was a 47 dB average room noise
 level across the recordings. In our new recordings, we had 6 speakers 
under the age of 30, 3 of whom were male and 3 were female. The 
collected samples were converted to MFCC representation for each 
microphone signal, so that we could compare single microphone and dual 
microphone performance.</p><p id="5a27" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">In
 our system, the decoder (DNN) uses relevant features from the encoded 
data — the data that was generated by the encoder (CNN) — in order to 
differentiate speakers in the original audio by placing them within 
buckets</p><figure class="ob oc od oe of fx fp fq paragraph-image"><div class="fp fq op"><picture><source srcset="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%20CbyA3KgMF4lui5yQ.webp 640w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520CbyA3KgMF4lui5yQ_003.webp 720w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520CbyA3KgMF4lui5yQ_004.webp 750w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520CbyA3KgMF4lui5yQ_006.webp 786w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520CbyA3KgMF4lui5yQ_007.webp 828w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520CbyA3KgMF4lui5yQ_002.webp 1100w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520CbyA3KgMF4lui5yQ_005.webp 898w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 449px" type="image/webp"><source data-testid="og" srcset="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520CbyA3KgMF4lui5yQ_003.png 640w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520CbyA3KgMF4lui5yQ_007.png 720w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%20CbyA3KgMF4lui5yQ.png 750w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520CbyA3KgMF4lui5yQ_004.png 786w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520CbyA3KgMF4lui5yQ_006.png 828w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520CbyA3KgMF4lui5yQ_005.png 1100w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520CbyA3KgMF4lui5yQ_002.png 898w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 449px"><img alt="" class="bg gc gd c" width="449" height="312" loading="lazy" role="presentation" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520CbyA3KgMF4lui5yQ_008.png"></picture></div><figcaption class="og oh oi fp fq oj ok be b bf z dw" data-selectable-paragraph="">Block
 diagram showing the MFCC input for 2 audio snippets concatenated before
 entering an encoder, followed by a decoder and a softmax at the output.
 The width of the output was the same as then number of possible 
individuals (speakers) in each experiment.</figcaption></figure><p id="d2e0" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">For each experiment we used <a class="af nz" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py" rel="noopener ugc nofollow" target="_blank">K-fold cross validation</a> to make sure the results were valid. The results for 1 microphone are shown below.</p><figure class="ob oc od oe of fx fp fq paragraph-image"><div class="fp fq oq"><picture><source srcset="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%20845mRIjAlmT8NuBH.webp 640w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520845mRIjAlmT8NuBH_004.webp 720w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520845mRIjAlmT8NuBH_005.webp 750w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520845mRIjAlmT8NuBH_007.webp 786w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520845mRIjAlmT8NuBH_002.webp 828w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520845mRIjAlmT8NuBH_003.webp 1100w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520845mRIjAlmT8NuBH_006.webp 1270w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 635px" type="image/webp"><source data-testid="og" srcset="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520845mRIjAlmT8NuBH_005.png 640w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520845mRIjAlmT8NuBH_004.png 720w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520845mRIjAlmT8NuBH_008.png 750w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%20845mRIjAlmT8NuBH.png 786w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520845mRIjAlmT8NuBH_006.png 828w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520845mRIjAlmT8NuBH_003.png 1100w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520845mRIjAlmT8NuBH_007.png 1270w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 635px"><img alt="" class="bg gc gd c" width="635" height="439" loading="lazy" role="presentation" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520845mRIjAlmT8NuBH_002.png"></picture></div><figcaption class="og oh oi fp fq oj ok be b bf z dw" data-selectable-paragraph="">Test results for a single microphone (one MFCC input).</figcaption></figure><p id="3edd" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">And now let’s look at the results for 2 microphones:</p><figure class="ob oc od oe of fx fp fq paragraph-image"><div class="fp fq or"><picture><source srcset="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%20v-UKqhWxOPq0pmfO.webp 640w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520v-UKqhWxOPq0pmfO_007.webp 720w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520v-UKqhWxOPq0pmfO_004.webp 750w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520v-UKqhWxOPq0pmfO_006.webp 786w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520v-UKqhWxOPq0pmfO_003.webp 828w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520v-UKqhWxOPq0pmfO_005.webp 1100w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520v-UKqhWxOPq0pmfO_002.webp 1280w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 640px" type="image/webp"><source data-testid="og" srcset="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520v-UKqhWxOPq0pmfO_002.png 640w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520v-UKqhWxOPq0pmfO_004.png 720w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%20v-UKqhWxOPq0pmfO.png 750w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520v-UKqhWxOPq0pmfO_005.png 786w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520v-UKqhWxOPq0pmfO_007.png 828w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520v-UKqhWxOPq0pmfO_003.png 1100w, Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520v-UKqhWxOPq0pmfO_006.png 1280w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 640px"><img alt="" class="bg gc gd c" width="640" height="443" loading="lazy" role="presentation" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%2520v-UKqhWxOPq0pmfO_002.png"></picture></div><figcaption class="og oh oi fp fq oj ok be b bf z dw" data-selectable-paragraph="">Test results for a dual microphone (two MFCC inputs).</figcaption></figure><p id="ee91" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">The
 first thing we notice when comparing single and dual microphone results
 is that the model performed better when given audio from 2 microphone 
sources as opposed to a single microphone source. That’s good news. It 
means our idea to use 2 microphones is not dumb. We also see in both 
results a degradation in performance as the number of possible speakers 
(buckets) goes up. As the number of speaker classes increases, the 
model’s accuracy decreases. Digging for a more general conclusion, we 
found that a CAE can differentiate speakers in audio, given a small 
sample size of audio collected from 2 microphones simultaneously.</p><p id="e5bb" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">Hopefully
 this article gave you a better sense of what the paper was about, what 
we figured out, and how we did it. This work was generously funded by 
Natural Sciences and Engineering Research Council of Canada (NSERC) and 
Unified Computer Intelligence Corporation (<a class="af nz" href="http://www.ucic.io/" rel="noopener ugc nofollow" target="_blank">UCIC.io</a>). Since this project started, Mohamed has come to work at <a class="af nz" href="http://lemay.ai/" rel="noopener ugc nofollow" target="_blank">lemay.ai</a>, and <a class="af nz" href="https://stallion.ai/en/team" rel="noopener ugc nofollow" target="_blank">stallion.ai</a>.</p><p id="6481" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">It was really useful to attend this <a class="af nz" href="https://www.merriam-webster.com/dictionary/biennial" rel="noopener ugc nofollow" target="_blank">biennial</a> IEEE conference. It was more technical than the last conference I went to (<a class="af nz" href="https://torontomachinelearning.com/" rel="noopener ugc nofollow" target="_blank">TMLS2018</a> — more on that trip <a class="af nz" rel="noopener" target="_blank" href="https://towardsdatascience.com/pitching-artificial-intelligence-to-business-people-f8ddd8fb2da2">here</a>)
 and a bit more than one third the size of TMLS. But I did enjoy both 
conferences. I met some really interesting people, saw some great talks,
 and I can tell you from this experience that a lot is changing in the 
signal processing field. There is still excellent feature engineering 
work going on, and also a whole whack of new papers on ML/AI approaches 
to speech and signal processing. There were also some excellent talks on
 the special session on deep learning. Some of the presenters I 
recognised half way through as people I saw lecturing in youtube videos.
 It’s like nerdy celebrity watching. Very exciting times.</p><p id="92a8" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">If you liked this article on my recent paper, then have a look at some of my most read past articles, like “<a class="af nz" href="https://medium.com/towards-data-science/how-to-price-an-ai-project-f7270cb630a4" rel="noopener">How to Price an AI Project</a>” and “<a class="af nz" href="https://medium.com/towards-data-science/why-hire-an-ai-consultant-50e155e17b39" rel="noopener">How to Hire an AI Consultant</a>.”</p><p id="c4de" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">Until next time!</p><p id="4755" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">-Daniel</p><p id="8427" class="pw-post-body-paragraph ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np fk bj" data-selectable-paragraph="">Other articles you may enjoy:</p><ul class=""><li id="167e" class="ms mt gg mu b mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np os ot ou bj" data-selectable-paragraph=""><a class="af nz" rel="noopener" target="_blank" href="https://towardsdatascience.com/artificial-intelligence-and-bad-data-fbf2564c541a">Artificial Intelligence and Bad Data</a></li><li id="70d3" class="ms mt gg mu b mv ov mx my mz ow nb nc nd ox nf ng nh oy nj nk nl oz nn no np os ot ou bj" data-selectable-paragraph=""><a class="af nz" rel="noopener" target="_blank" href="https://towardsdatascience.com/image-datasets-for-artificial-intelligence-bbb12615edd7">Image Datasets for Artificial Intelligence</a></li><li id="4172" class="ms mt gg mu b mv ov mx my mz ow nb nc nd ox nf ng nh oy nj nk nl oz nn no np os ot ou bj" data-selectable-paragraph=""><a class="af nz" href="https://medium.com/towards-data-science/artificial-intelligence-get-your-users-to-label-your-data-b5fa7c0c9e00" rel="noopener">Artificial Intelligence: Get your users to label your data</a></li></ul></div></div></div></div></section></div></div></article><div class="ab ca"><div class="ch bg ew ex ey ez"></div></div></div><div class="ab ca"><div class="ch bg ew ex ey ez"><div class="pa pb ab is"><div class="pc ab"><a class="pd ax am ao" href="https://medium.com/tag/machine-learning?source=post_page-----68b2dede498f---------------machine_learning-----------------" rel="noopener follow"><div class="pe ee cw pf fb pg ph be b bf z bj pi">Machine Learning</div></a></div><div class="pc ab"><a class="pd ax am ao" href="https://medium.com/tag/deep-learning?source=post_page-----68b2dede498f---------------deep_learning-----------------" rel="noopener follow"><div class="pe ee cw pf fb pg ph be b bf z bj pi">Deep Learning</div></a></div><div class="pc ab"><a class="pd ax am ao" href="https://medium.com/tag/data-science?source=post_page-----68b2dede498f---------------data_science-----------------" rel="noopener follow"><div class="pe ee cw pf fb pg ph be b bf z bj pi">Data Science</div></a></div><div class="pc ab"><a class="pd ax am ao" href="https://medium.com/tag/artificial-intelligence?source=post_page-----68b2dede498f---------------artificial_intelligence-----------------" rel="noopener follow"><div class="pe ee cw pf fb pg ph be b bf z bj pi">Artificial Intelligence</div></a></div><div class="pc ab"><a class="pd ax am ao" href="https://medium.com/tag/towards-data-science?source=post_page-----68b2dede498f---------------towards_data_science-----------------" rel="noopener follow"><div class="pe ee cw pf fb pg ph be b bf z bj pi">Towards Data Science</div></a></div></div></div></div><div class="l"></div><footer class="pj pk pl pm pn po pp pq pr ab q ps ib c"><div class="l ae"><div class="ab ca"><div class="ch bg ew ex ey ez"><div class="ab co pt"><div class="ab q kn"><div class="pu l"><span class="l pv pw px e d"><div class="ab q kn ko"><div class="pw-multi-vote-icon ee iw kp kq kr"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="83" aria-labelledby="83"><button class="ks ao ku ut uu ky am kz la lb kr" data-testid="footerClapButton"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></button></div></div></div></div><div class="pw-multi-vote-count l lc ld le lf lg lh li"><div><div class="bl" aria-hidden="false" aria-describedby="84" aria-labelledby="84"><p class="be b dx z dw"><button class="af ag ah ai aj ak al am an ao ap aq ar as at uv uw">291<span class="l h g f py pz"></span></button></p></div></div></div></div></span><span class="l h g f py pz"><div class="ab q kn ko"><div class="pw-multi-vote-icon ee iw kp kq kr"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="85" aria-labelledby="85"><button class="ks ao ku ut uu ky am kz la lb kr" data-testid="footerClapButton"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></button></div></div></div></div><div class="pw-multi-vote-count l lc ld le lf lg lh li"><div><div class="bl" aria-hidden="false" aria-describedby="86" aria-labelledby="86"><p class="be b dx z dw"><button class="af ag ah ai aj ak al am an ao ap aq ar as at uv uw">291</button></p></div></div></div></div></span></div><div class="bp ab"><div><div class="bl" aria-hidden="false" aria-describedby="10" aria-labelledby="10"><button class="ao ks ll lm ab q ef ln lo" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" class="lk"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b bf z dw"><span class="pw-responses-count lj lk">1</span></p></button></div></div></div></div><div class="ab q"><div class="qa l ip"><div><div class="bl" aria-hidden="false" aria-describedby="11" aria-labelledby="11"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" data-testid="footerBookmarkButton" class="af ef ah ai aj ak al lq an ao ap im lr ls lt"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lu"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="qa l ip"><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false" aria-describedby="12" aria-labelledby="12"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="footerSocialShareButton" class="af ef ah ai aj ak al lq an ao ap im mb mc lo md"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg></button></div></div></div></div><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="90" aria-labelledby="90"><button aria-label="More options" data-testid="footerStoryOptionsButton" class="af ef ah ai aj ak al lq an ao ap im mb mc lo md"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div></div></footer><div class="qb qc qd qe qf l bw"><div class="ab ca"><div class="ch bg ew ex ey ez"><div class="ck ab qg co"><div class="ab hr"><a href="https://medium.com/@lemaysolutions?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><div class="l qh qi bx qj hv"><div class="l ee"><img alt="Daniel Shapiro, PhD" class="l eq bx qk ql cw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20moqpKxEKi4uSXIhNBwgOkQ.jpg" width="72" height="72" loading="lazy"><div class="hw bx l qk ql eo n hx ep"></div></div></div></a><a href="https://towardsdatascience.com/?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><div class="qm ab ee"><div><div class="bl" aria-hidden="false" aria-describedby="14" aria-labelledby="14"><div class="l qn qo bx qj ib"><div class="l ee"><img alt="Towards Data Science" class="l eq bx by bz cw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520CJe3891yB1A1mzMdqemkdg_002.jpg" width="32" height="32" loading="lazy"><div class="hw bx l by bz eo n hx ep"></div></div></div></div></div></div></a></div><div class="j i d"><div class="ab"><button class="be b bf z ud pe uo uj up uq ur us qy im qz ra rb rc rd re eq bl om oh">Follow</button><div class="dv l"><div><div><div class="bl" aria-hidden="false" aria-describedby="338" aria-labelledby="338"><div class="l"><button class="be b bf z ud am uo uj up uq ur us qy im qz ra rb rd re eq bl om oh" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="un qo qn"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></div></div></div></div></div></div></div></div><div class="ab cm co"><div class="l"><div class="ab q"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab q" href="https://medium.com/@lemaysolutions?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><h2 class="pw-author-name be rg rh ri rj bj"><span class="fk">Written by <!-- -->Daniel Shapiro, PhD</span></h2></a></div><div class="pc ab"><div class="l ip"><span class="pw-follower-count be b bf z bj"><a class="af ag ah ai aj ak al am an ao ap aq ar ih" href="https://medium.com/@lemaysolutions/followers?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow">4.8K Followers</a></span></div><div class="be b bf z ix iy iz ab jb jc jd je dw iv"><span class="ii l" aria-hidden="true"><span class="be b bf z dw">·</span></span><span class="l ip">Writer for </span><div><div class="l" aria-hidden="false" aria-describedby="16" aria-labelledby="16"><a class="af ag ah ai aj ak al am an ao ap aq ar ih ab q" href="https://towardsdatascience.com/?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><p class="be b bf z ix iy iz ja jb jc jd je bj">Towards Data Science</p></a></div></div></div></div><div class="rk l"><p class="be b bf z bj">Passionate About Machine Learning R&amp;D and Value Creation. ✍ <a class="af ag ah ai aj ak al am an ao ap aq ar nz fl" href="mailto:daniel@lemay.ai" rel="noopener  ugc nofollow">daniel@lemay.ai</a> ⬱ <a class="af ag ah ai aj ak al am an ao ap aq ar nz fl" href="https://lemay.ai/" rel="noopener  ugc nofollow">https://lemay.ai</a></p></div></div><div class="h k"><div class="ab"><button class="be b bf z ud pe uo uj up uq ur us qy im qz ra rb rc rd re eq bl om oh">Follow</button><div class="dv l"><div><div><div class="bl" aria-hidden="false" aria-describedby="340" aria-labelledby="340"><div class="l"><button class="be b bf z ud am uo uj up uq ur us qy im qz ra rb rd re eq bl om oh" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="un qo qn"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></div></div></div></div></div></div></div></div><div class="rl bg rm fs ft fu fv fw"></div></div></div><div class="ab ca"><div class="ch bg ew ex ey ez"><div class="ux uy l"><h2 class="be rg if z gf bj">More from Daniel Shapiro, PhD and Towards Data Science</h2></div><div class="uz ab kn is va vb vc vd ve vf vg vh vi vj vk vl vm vn vo"><div class="vp vq vr vs vt vu vv vw vx vy vz wa wb wc wd we wf wg wh wi wj"><div class="wk wl wm wn wo dy l"><article class="dy"><div class="dy pr l"><div class="bg dy"><div class="dy l"><div class="ee dy wp wq wr ws wt wu wv ww wx wy wz xa xb" role="link" data-href="https://towardsdatascience.com/how-to-price-an-ai-project-f7270cb630a4" tabindex="0"><div class="xc"><div aria-label="How to Price an AI Project"><div class="xe xf xg xh xi"><img alt="How to Price an AI Project" class="bg xj xk xl xm bw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%20cTBjFWhMPXfaM-LV.jpg" loading="lazy"></div></div></div><div class="xd ab ca cn"><div class="ab cn xn bg xo xp xq xr"><div class="xs xt xu xv xw ab q"><div class="pd l"><div><div class="l" aria-hidden="false" aria-describedby="119" aria-labelledby="119"><a tabindex="-1" href="https://medium.com/@lemaysolutions?source=author_recirc-----68b2dede498f----0---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------" rel="noopener follow"><div class="l ee"><img alt="Daniel Shapiro, PhD" class="l eq bx xx xy cw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520moqpKxEKi4uSXIhNBwgOkQ_003.jpg" width="20" height="20" loading="lazy"><div class="em bx l xx xy eo n ax ep"></div></div></a></div></div></div><div class="xz l"><div><div class="l" aria-hidden="false" aria-describedby="120" aria-labelledby="120"><a class="af ag ah ai aj ak al am an ao ap aq ar ih ab q" href="https://medium.com/@lemaysolutions?source=author_recirc-----68b2dede498f----0---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------" rel="noopener follow"><p class="be b dx z ix iy iz ja jb jc jd je bj">Daniel Shapiro, PhD</p></a></div></div></div><div class="xz l"><p class="be b dx z dw">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="121" aria-labelledby="121"><a class="af ag ah ai aj ak al am an ao ap aq ar ih ab q" href="https://towardsdatascience.com/?source=author_recirc-----68b2dede498f----0---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------" rel="noopener follow"><p class="be b dx z ix iy iz ja jb jc jd je bj">Towards Data Science</p></a></div></div></div></div><div class="ya l yb yc yd ye yf fk"><div class="yg yh yi yj yk yl ym yn"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/how-to-price-an-ai-project-f7270cb630a4?source=author_recirc-----68b2dede498f----0---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------"><div title=""><h2 class="be gh yo yp yq yr ys yt yu yv yw yx nd yy yz za zb nh zc zd ze zf nl zg zh zi zj ix iz ja jc je bj">How to Price an AI Project</h2></div><div class="zk l"><h3 class="be b if z ix zl iz ja zm jc je dw">I
 have been asked many times by clients to provide fixed price estimates 
for large Machine Learning (ML) projects. This is really tricky…</h3></div></a></div></div><span class="be b dx z dw"><div class="ht ab co ae"><div class="ab q"><span>Aug 4, 2017</span><div class=""><div class="ee zn dg ab q"><div class="eo tj zo ab q"><div class="aw dg di l cw"></div></div><a class="eo ll zo ab q" tabindex="-1" rel="noopener follow" href="https://towardsdatascience.com/how-to-price-an-ai-project-f7270cb630a4?source=author_recirc-----68b2dede498f----0---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------"><div class="aw l"><div><div class="ab" aria-hidden="false" aria-describedby="205" aria-labelledby="205"><div class="ab q ee"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3.67 10.17l2.14 2.14c1.72 1.72 4.33 2.43 5.96.8a4.38 4.38 0 0 0 .76-5.38L10.7 4.25c-.35-.53-.85-1.22-1.33-.96-.5.26 0 1.56 0 1.56l.78 1.93-3.73-3.91C5.6 1.9 4.96 1.76 4.5 2.22c-.33.33-.26.85.48 1.6.5.5 1.89 1.95 1.89 1.95.17.18.08.49-.1.66-.09.1-.2.15-.34.16a.43.43 0 0 1-.31-.13l-2.8-2.87c-.35-.35-.8-.54-1.2-.15-.4.4-.27 1.06.11 1.44l2.69 2.67.06.06c.17.18.27.63.1.8-.2.2-.46.33-.69.28a.92.92 0 0 1-.44-.28S2.5 6.84 1.89 6.23c-.4-.4-.9-.33-1.23 0-.52.52.27 1.28 1.73 2.7.39.36.82.77 1.28 1.24zm8.47-7.22c.38-.3.95-.28 1.3.24l1.57 3a5 5 0 0 1-.48 5.24l-.03.04c-.21.27-.35.43-.74.61 1.38-1.85.96-3.47-.25-5.45l-1.57-2.75v-.04c-.02-.3-.04-.7.2-.9z" fill="#6B6B6B"></path></svg><span style="margin-left: 4px;">1.2K</span></div></div></div></div><div class="aw l"><div><div class="ab" aria-hidden="false" aria-describedby="122" aria-labelledby="122"><div class="ab q ee"><svg width="16" height="16" viewBox="0 0 16 16" fill="#6B6B6B"><path d="M12.34 11.46A5.28 5.28 0 0 0 14 7.53C14 4.48 11.4 2 8.05 2 4.71 2 2 4.48 2 7.53c0 3.05 2.71 5.52 6.06 5.52.6 0 1.18-.08 1.76-.23.17.14.35.29.55.41.78.51 1.63.77 2.51.77.17 0 .3-.08.36-.22a.37.37 0 0 0-.03-.38 4.73 4.73 0 0 1-.86-1.96v.02z" fill="#6B6B6B"></path></svg><span style="margin-left: 4px;">5</span></div></div></div></div></a></div></div></div><div class="ab q zp zq"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="123" aria-labelledby="123"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al zr an ao ap im lr ls lt"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lu"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="zs l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="207" aria-labelledby="207"><button aria-label="More options" class="af ef ah ai aj ak al zr an ao ap im mb mc lo md"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></span><div class="j i d"><div class="rl bg rm lk"></div></div></div></div></div></div></div></div></article></div></div><div class="vp vq vr vs vt vu vv vw vx vy vz wa wb wc wd we wf wg wh wi wj"><div class="wk wl wm wn wo dy l"><article class="dy"><div class="dy pr l"><div class="bg dy"><div class="dy l"><div class="ee dy wp wq wr ws wt wu wv ww wx wy wz xa xb" role="link" data-href="https://towardsdatascience.com/python-one-billion-row-challenge-from-10-minutes-to-4-seconds-0718662b303e" tabindex="0"><div class="xc"><div aria-label="Python One Billion Row Challenge — From 10 Minutes to 4 Seconds"><div class="xe xf xg xh xi"><img alt="Python One Billion Row Challenge — From 10 Minutes to 4 Seconds" class="bg xj xk xl xm bw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%20W7gkPGcHZpQGe03W.jpg" loading="lazy"></div></div></div><div class="xd ab ca cn"><div class="ab cn xn bg xo xp xq xr"><div class="xs xt xu xv xw ab q"><div class="pd l"><div><div class="l" aria-hidden="false" aria-describedby="125" aria-labelledby="125"><a tabindex="-1" href="https://medium.com/@radecicdario?source=author_recirc-----68b2dede498f----1---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------" rel="noopener follow"><div class="l ee"><img alt="Dario Radečić" class="l eq bx xx xy cw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/2%20VmdbajrpX9nwOc9UtkV3Yg.png" width="20" height="20" loading="lazy"><div class="em bx l xx xy eo n ax ep"></div></div></a></div></div></div><div class="xz l"><div><div class="l" aria-hidden="false" aria-describedby="126" aria-labelledby="126"><a class="af ag ah ai aj ak al am an ao ap aq ar ih ab q" href="https://medium.com/@radecicdario?source=author_recirc-----68b2dede498f----1---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------" rel="noopener follow"><p class="be b dx z ix iy iz ja jb jc jd je bj">Dario Radečić</p><div class="zt zu l"><div class="ab zv"><div class="ab"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path d="M15.16 8c0 .65-.46 1.14-.86 1.57-.23.25-.47.5-.56.72-.1.22-.09.55-.1.88 0 .6-.01 1.3-.48 1.78-.48.48-1.16.5-1.75.5-.32 0-.65.01-.86.1-.2.07-.46.33-.7.57-.42.41-.9.88-1.54.88s-1.12-.47-1.54-.88a2.87 2.87 0 0 0-.7-.58c-.22-.09-.54-.08-.87-.09-.59 0-1.27-.02-1.74-.5s-.48-1.17-.49-1.78c0-.33-.01-.67-.1-.88-.07-.2-.32-.47-.55-.71-.4-.44-.87-.93-.87-1.58s.46-1.14.87-1.58c.23-.24.47-.5.56-.71.09-.22.08-.55.09-.88 0-.6.02-1.3.49-1.78s1.15-.5 1.74-.5c.33 0 .66-.01.86-.1.2-.08.47-.33.7-.57.43-.41.91-.88 1.55-.88.63 0 1.12.47 1.54.88.24.24.49.48.7.58.22.09.54.08.86.09.6 0 1.27.02 1.75.5.47.48.48 1.17.49 1.78 0 .33 0 .67.09.88.08.2.33.47.56.71.4.44.86.93.86 1.58z" fill="#437AFF"></path><path d="M7.33 10.5c.2 0 .38.08.52.22.13.14.21.33.21.53 0 .07.03.13.07.18a.24.24 0 0 0 .35 0 .25.25 0 0 0 .07-.18c0-.2.08-.39.22-.53a.73.73 0 0 1 .52-.22h1.96c.13 0 .25-.05.34-.15a.5.5 0 0 0 .15-.35V6a.5.5 0 0 0-.15-.35.48.48 0 0 0-.34-.15H9.78c-.33 0-.64.13-.87.37-.23.23-.36.55-.36.88v2.5c0 .07-.02.13-.07.18a.24.24 0 0 1-.35 0 .25.25 0 0 1-.07-.18v-2.5c0-.33-.13-.65-.36-.88a1.21 1.21 0 0 0-.86-.37H5.37a.48.48 0 0 0-.35.15.5.5 0 0 0-.14.35v4c0 .13.05.26.14.35.1.1.22.15.35.15h1.96z" fill="#fff"></path></svg></div></div></div></a></div></div></div><div class="xz l"><p class="be b dx z dw">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="127" aria-labelledby="127"><a class="af ag ah ai aj ak al am an ao ap aq ar ih ab q" href="https://towardsdatascience.com/?source=author_recirc-----68b2dede498f----1---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------" rel="noopener follow"><p class="be b dx z ix iy iz ja jb jc jd je bj">Towards Data Science</p></a></div></div></div></div><div class="ya l yb yc yd ye yf fk"><div class="yg yh yi yj yk yl ym yn"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/python-one-billion-row-challenge-from-10-minutes-to-4-seconds-0718662b303e?source=author_recirc-----68b2dede498f----1---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------"><div title=""><h2 class="be gh yo yp yq yr ys yt yu yv yw yx nd yy yz za zb nh zc zd ze zf nl zg zh zi zj ix iz ja jc je bj">Python One Billion Row Challenge — From 10 Minutes to 4 Seconds</h2></div><div class="zk l"><h3 class="be b if z ix zl iz ja zm jc je dw">The one billion row challenge is exploding in popularity. How well does Python stack up?</h3></div></a></div></div><span class="be b dx z dw"><div class="ht ab co ae"><div class="ab q"><div class="zw pr ab"><div class="bl" aria-hidden="false" aria-describedby="128" aria-labelledby="128"><button class="l ax ao am" aria-label="Member-only story"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="129" aria-labelledby="129"><svg width="16" height="16" viewBox="0 0 64 64" fill="none"><path d="M39.64 40.83L33.87 56.7a1.99 1.99 0 0 1-3.74 0l-5.77-15.87a2.02 2.02 0 0 0-1.2-1.2L7.3 33.88a1.99 1.99 0 0 1 0-3.74l15.87-5.77a2.02 2.02 0 0 0 1.2-1.2L30.12 7.3a1.99 1.99 0 0 1 3.74 0l5.77 15.87a2.02 2.02 0 0 0 1.2 1.2l15.86 5.76a1.99 1.99 0 0 1 0 3.74l-15.87 5.77a2.02 2.02 0 0 0-1.2 1.2z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span>May 8</span><div class=""><div class="ee zn dg ab q"><div class="eo tj zo ab q"><div class="aw dg di l cw"></div></div><a class="eo ll zo ab q" tabindex="-1" rel="noopener follow" href="https://towardsdatascience.com/python-one-billion-row-challenge-from-10-minutes-to-4-seconds-0718662b303e?source=author_recirc-----68b2dede498f----1---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------"><div class="aw l"><div><div class="ab" aria-hidden="false" aria-describedby="208" aria-labelledby="208"><div class="ab q ee"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3.67 10.17l2.14 2.14c1.72 1.72 4.33 2.43 5.96.8a4.38 4.38 0 0 0 .76-5.38L10.7 4.25c-.35-.53-.85-1.22-1.33-.96-.5.26 0 1.56 0 1.56l.78 1.93-3.73-3.91C5.6 1.9 4.96 1.76 4.5 2.22c-.33.33-.26.85.48 1.6.5.5 1.89 1.95 1.89 1.95.17.18.08.49-.1.66-.09.1-.2.15-.34.16a.43.43 0 0 1-.31-.13l-2.8-2.87c-.35-.35-.8-.54-1.2-.15-.4.4-.27 1.06.11 1.44l2.69 2.67.06.06c.17.18.27.63.1.8-.2.2-.46.33-.69.28a.92.92 0 0 1-.44-.28S2.5 6.84 1.89 6.23c-.4-.4-.9-.33-1.23 0-.52.52.27 1.28 1.73 2.7.39.36.82.77 1.28 1.24zm8.47-7.22c.38-.3.95-.28 1.3.24l1.57 3a5 5 0 0 1-.48 5.24l-.03.04c-.21.27-.35.43-.74.61 1.38-1.85.96-3.47-.25-5.45l-1.57-2.75v-.04c-.02-.3-.04-.7.2-.9z" fill="#6B6B6B"></path></svg><span style="margin-left: 4px;">3.7K</span></div></div></div></div><div class="aw l"><div><div class="ab" aria-hidden="false" aria-describedby="130" aria-labelledby="130"><div class="ab q ee"><svg width="16" height="16" viewBox="0 0 16 16" fill="#6B6B6B"><path d="M12.34 11.46A5.28 5.28 0 0 0 14 7.53C14 4.48 11.4 2 8.05 2 4.71 2 2 4.48 2 7.53c0 3.05 2.71 5.52 6.06 5.52.6 0 1.18-.08 1.76-.23.17.14.35.29.55.41.78.51 1.63.77 2.51.77.17 0 .3-.08.36-.22a.37.37 0 0 0-.03-.38 4.73 4.73 0 0 1-.86-1.96v.02z" fill="#6B6B6B"></path></svg><span style="margin-left: 4px;">46</span></div></div></div></div></a></div></div></div><div class="ab q zp zq"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="131" aria-labelledby="131"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al zr an ao ap im lr ls lt"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lu"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="zs l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="210" aria-labelledby="210"><button aria-label="More options" class="af ef ah ai aj ak al zr an ao ap im mb mc lo md"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></span><div class="j i d"><div class="rl bg rm lk"></div></div></div></div></div></div></div></div></article></div></div><div class="vp vq vr vs vt vu vv vw vx vy vz wa wb wc wd we wf wg wh wi wj"><div class="wk wl wm wn wo dy l"><article class="dy"><div class="dy pr l"><div class="bg dy"><div class="dy l"><div class="ee dy wp wq wr ws wt wu wv ww wx wy wz xa xb" role="link" data-href="https://towardsdatascience.com/kolmogorov-arnold-networks-the-latest-advance-in-neural-networks-simply-explained-f083cf994a85" tabindex="0"><div class="xc"><div aria-label="Kolmogorov-Arnold Networks: the latest advance in Neural Networks, simply explained"><div class="xe xf xg xh xi"><img alt="Kolmogorov-Arnold Networks: the latest advance in Neural Networks, simply explained" class="bg xj xk xl xm bw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20bdY9iqbeQHs5Lwzz3h9sbw.png" loading="lazy"></div></div></div><div class="xd ab ca cn"><div class="ab cn xn bg xo xp xq xr"><div class="xs xt xu xv xw ab q"><div class="pd l"><div><div class="l" aria-hidden="false" aria-describedby="133" aria-labelledby="133"><a tabindex="-1" href="https://medium.com/@theo.wolf?source=author_recirc-----68b2dede498f----2---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------" rel="noopener follow"><div class="l ee"><img alt="Theo Wolf" class="l eq bx xx xy cw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20fvRtxLkYfXSgXRFpRO3IqA.jpg" width="20" height="20" loading="lazy"><div class="em bx l xx xy eo n ax ep"></div></div></a></div></div></div><div class="xz l"><div><div class="l" aria-hidden="false" aria-describedby="134" aria-labelledby="134"><a class="af ag ah ai aj ak al am an ao ap aq ar ih ab q" href="https://medium.com/@theo.wolf?source=author_recirc-----68b2dede498f----2---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------" rel="noopener follow"><p class="be b dx z ix iy iz ja jb jc jd je bj">Theo Wolf</p></a></div></div></div><div class="xz l"><p class="be b dx z dw">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="135" aria-labelledby="135"><a class="af ag ah ai aj ak al am an ao ap aq ar ih ab q" href="https://towardsdatascience.com/?source=author_recirc-----68b2dede498f----2---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------" rel="noopener follow"><p class="be b dx z ix iy iz ja jb jc jd je bj">Towards Data Science</p></a></div></div></div></div><div class="ya l yb yc yd ye yf fk"><div class="yg yh yi yj yk yl ym yn"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/kolmogorov-arnold-networks-the-latest-advance-in-neural-networks-simply-explained-f083cf994a85?source=author_recirc-----68b2dede498f----2---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------"><div title="Kolmogorov-Arnold Networks: the latest advance in Neural Networks, simply explained"><h2 class="be gh yo yp yq yr ys yt yu yv yw yx nd yy yz za zb nh zc zd ze zf nl zg zh zi zj ix iz ja jc je bj">Kolmogorov-Arnold Networks: the latest advance in Neural Networks, simply explained</h2></div><div class="zk l"><h3 class="be b if z ix zl iz ja zm jc je dw">The new type of network that is making waves in the ML world.</h3></div></a></div></div><span class="be b dx z dw"><div class="ht ab co ae"><div class="ab q"><div class="zw pr ab"><div class="bl" aria-hidden="false" aria-describedby="136" aria-labelledby="136"><button class="l ax ao am" aria-label="Member-only story"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="137" aria-labelledby="137"><svg width="16" height="16" viewBox="0 0 64 64" fill="none"><path d="M39.64 40.83L33.87 56.7a1.99 1.99 0 0 1-3.74 0l-5.77-15.87a2.02 2.02 0 0 0-1.2-1.2L7.3 33.88a1.99 1.99 0 0 1 0-3.74l15.87-5.77a2.02 2.02 0 0 0 1.2-1.2L30.12 7.3a1.99 1.99 0 0 1 3.74 0l5.77 15.87a2.02 2.02 0 0 0 1.2 1.2l15.86 5.76a1.99 1.99 0 0 1 0 3.74l-15.87 5.77a2.02 2.02 0 0 0-1.2 1.2z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span>May 12</span><div class=""><div class="ee zn dg ab q"><div class="eo tj zo ab q"><div class="aw dg di l cw"></div></div><a class="eo ll zo ab q" tabindex="-1" rel="noopener follow" href="https://towardsdatascience.com/kolmogorov-arnold-networks-the-latest-advance-in-neural-networks-simply-explained-f083cf994a85?source=author_recirc-----68b2dede498f----2---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------"><div class="aw l"><div><div class="ab" aria-hidden="false" aria-describedby="211" aria-labelledby="211"><div class="ab q ee"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3.67 10.17l2.14 2.14c1.72 1.72 4.33 2.43 5.96.8a4.38 4.38 0 0 0 .76-5.38L10.7 4.25c-.35-.53-.85-1.22-1.33-.96-.5.26 0 1.56 0 1.56l.78 1.93-3.73-3.91C5.6 1.9 4.96 1.76 4.5 2.22c-.33.33-.26.85.48 1.6.5.5 1.89 1.95 1.89 1.95.17.18.08.49-.1.66-.09.1-.2.15-.34.16a.43.43 0 0 1-.31-.13l-2.8-2.87c-.35-.35-.8-.54-1.2-.15-.4.4-.27 1.06.11 1.44l2.69 2.67.06.06c.17.18.27.63.1.8-.2.2-.46.33-.69.28a.92.92 0 0 1-.44-.28S2.5 6.84 1.89 6.23c-.4-.4-.9-.33-1.23 0-.52.52.27 1.28 1.73 2.7.39.36.82.77 1.28 1.24zm8.47-7.22c.38-.3.95-.28 1.3.24l1.57 3a5 5 0 0 1-.48 5.24l-.03.04c-.21.27-.35.43-.74.61 1.38-1.85.96-3.47-.25-5.45l-1.57-2.75v-.04c-.02-.3-.04-.7.2-.9z" fill="#6B6B6B"></path></svg><span style="margin-left: 4px;">1.5K</span></div></div></div></div><div class="aw l"><div><div class="ab" aria-hidden="false" aria-describedby="138" aria-labelledby="138"><div class="ab q ee"><svg width="16" height="16" viewBox="0 0 16 16" fill="#6B6B6B"><path d="M12.34 11.46A5.28 5.28 0 0 0 14 7.53C14 4.48 11.4 2 8.05 2 4.71 2 2 4.48 2 7.53c0 3.05 2.71 5.52 6.06 5.52.6 0 1.18-.08 1.76-.23.17.14.35.29.55.41.78.51 1.63.77 2.51.77.17 0 .3-.08.36-.22a.37.37 0 0 0-.03-.38 4.73 4.73 0 0 1-.86-1.96v.02z" fill="#6B6B6B"></path></svg><span style="margin-left: 4px;">17</span></div></div></div></div></a></div></div></div><div class="ab q zp zq"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="139" aria-labelledby="139"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al zr an ao ap im lr ls lt"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lu"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="zs l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="213" aria-labelledby="213"><button aria-label="More options" class="af ef ah ai aj ak al zr an ao ap im mb mc lo md"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></span><div class="j i d"><div class="rl bg rm lk"></div></div></div></div></div></div></div></div></article></div></div><div class="vp vq vr vs vt vu vv vw vx vy vz wa wb wc wd we wf wg wh wi wj"><div class="wk wl wm wn wo dy l"><article class="dy"><div class="dy pr l"><div class="bg dy"><div class="dy l"><div class="ee dy wp wq wr ws wt wu wv ww wx wy wz xa xb" role="link" data-href="https://medium.com/@lemaysolutions/exploring-100-a-i-projects-01c8dee53af9" tabindex="0"><div class="xc"><div aria-label="Exploring 100+ A.I. Projects"><div class="xe xf xg xh xi"><img alt="Exploring 100+ A.I. Projects" class="bg xj xk xl xm bw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20TaEDFw8mqMfeIbo8j7Ex2w.png" loading="lazy"></div></div></div><div class="xd ab ca cn"><div class="ab cn xn bg xo xp xq xr"><div class="xs xt xu xv xw ab q"><div class="pd l"><div><div class="l" aria-hidden="false" aria-describedby="141" aria-labelledby="141"><a tabindex="-1" href="https://medium.com/@lemaysolutions?source=author_recirc-----68b2dede498f----3---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------" rel="noopener follow"><div class="l ee"><img alt="Daniel Shapiro, PhD" class="l eq bx xx xy cw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%2520moqpKxEKi4uSXIhNBwgOkQ_003.jpg" width="20" height="20" loading="lazy"><div class="em bx l xx xy eo n ax ep"></div></div></a></div></div></div><div class="xz l"><div><div class="l" aria-hidden="false" aria-describedby="142" aria-labelledby="142"><a class="af ag ah ai aj ak al am an ao ap aq ar ih ab q" href="https://medium.com/@lemaysolutions?source=author_recirc-----68b2dede498f----3---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------" rel="noopener follow"><p class="be b dx z ix iy iz ja jb jc jd je bj">Daniel Shapiro, PhD</p></a></div></div></div></div><div class="ya l yb yc yd ye yf fk"><div class="yg yh yi yj yk yl ym yn"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@lemaysolutions/exploring-100-a-i-projects-01c8dee53af9?source=author_recirc-----68b2dede498f----3---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------" rel="noopener follow"><div title=""><h2 class="be gh yo yp yq yr ys yt yu yv yw yx nd yy yz za zb nh zc zd ze zf nl zg zh zi zj ix iz ja jc je bj">Exploring 100+ A.I. Projects</h2></div><div class="zk l"><h3 class="be b if z ix zl iz ja zm jc je dw">Looking back at 8 years of A.I. projects at Lemay.ai</h3></div></a></div></div><span class="be b dx z dw"><div class="ht ab co ae"><div class="ab q"><span>Feb 12</span><div class=""><div class="ee zn dg ab q"><div class="eo tj zo ab q"><div class="aw dg di l cw"></div></div><a class="eo ll zo ab q" tabindex="-1" href="https://medium.com/@lemaysolutions/exploring-100-a-i-projects-01c8dee53af9?source=author_recirc-----68b2dede498f----3---------------------0f9b08fa_dddb_4b10_a775_c5b0b7624060-------" rel="noopener follow"><div class="aw l"><div><div class="ab" aria-hidden="false" aria-describedby="214" aria-labelledby="214"><div class="ab q ee"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3.67 10.17l2.14 2.14c1.72 1.72 4.33 2.43 5.96.8a4.38 4.38 0 0 0 .76-5.38L10.7 4.25c-.35-.53-.85-1.22-1.33-.96-.5.26 0 1.56 0 1.56l.78 1.93-3.73-3.91C5.6 1.9 4.96 1.76 4.5 2.22c-.33.33-.26.85.48 1.6.5.5 1.89 1.95 1.89 1.95.17.18.08.49-.1.66-.09.1-.2.15-.34.16a.43.43 0 0 1-.31-.13l-2.8-2.87c-.35-.35-.8-.54-1.2-.15-.4.4-.27 1.06.11 1.44l2.69 2.67.06.06c.17.18.27.63.1.8-.2.2-.46.33-.69.28a.92.92 0 0 1-.44-.28S2.5 6.84 1.89 6.23c-.4-.4-.9-.33-1.23 0-.52.52.27 1.28 1.73 2.7.39.36.82.77 1.28 1.24zm8.47-7.22c.38-.3.95-.28 1.3.24l1.57 3a5 5 0 0 1-.48 5.24l-.03.04c-.21.27-.35.43-.74.61 1.38-1.85.96-3.47-.25-5.45l-1.57-2.75v-.04c-.02-.3-.04-.7.2-.9z" fill="#6B6B6B"></path></svg><span style="margin-left: 4px;">115</span></div></div></div></div></a></div></div></div><div class="ab q zp zq"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="143" aria-labelledby="143"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al zr an ao ap im lr ls lt"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lu"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="zs l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="215" aria-labelledby="215"><button aria-label="More options" class="af ef ah ai aj ak al zr an ao ap im mb mc lo md"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div></div><div class="rl bg rm dj dk zx zy zz"></div><div class="ab iq ir aba abb abc"><a class="be b bf z bj pe abd abe abf uw ln abg us qy im abh abi abj rb abk abl abm abn abo rd re eq bl om oh" href="https://medium.com/@lemaysolutions?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><div class="l oh">See all from Daniel Shapiro, PhD</div></a><div class="abp abq abr abs abt abu abv abw abx li l"><a class="be b bf z bj pe abd abe abf uw ln abg us qy im abh abi abj rb abk abl abm abn abo rd re eq bl om oh" href="https://towardsdatascience.com/?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><div class="l oh">See all from Towards Data Science</div></a></div></div></div></div><div class="rl bg rm aby abz aca acb acc"></div><div class="ab ca"><div class="ch bg ew ex ey ez"><div class="acd ace l"><h2 class="be rg yo yp ys yt yu yx acf acg ach aci acj ack acl acm acn bj">Recommended from Medium</h2><div class="ob oc od oe of l"><div class="uz ab kn is va vb vc vd ve vf vg vh vi vj vk vl vm vn vo"><div class="vp vq vr vs vt vu vv vw vx vy vz wa wb wc wd we wf wg wh wi wj"><div class="wk wl wm wn wo dy l"><article class="dy"><div class="dy pr l"><div class="bg dy"><div class="dy l"><div class="ee dy wp wq wr ws wt wu wv ww wx wy wz xa xb" role="link" data-href="https://medium.com/intel-analytics-software/automatic-speech-recognition-using-openai-whisper-without-a-gpu-9d316a93860a" tabindex="0"><div class="xc"><div aria-label="Automatic Speech Recognition using OpenAI Whisper without a GPU"><div class="xe xf xg xh xi"><img alt="Automatic Speech Recognition using OpenAI Whisper without a GPU" class="bg xj xk xl xm bw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%20MTTeVeNJtS8gX2U_.png" loading="lazy"></div></div></div><div class="xd ab ca cn"><div class="ab cn xn bg xo xp xq xr"><div class="xs xt xu xv xw ab q"><div class="pd l"><div><div class="l" aria-hidden="false" aria-describedby="145" aria-labelledby="145"><a tabindex="-1" href="https://medium.com/@benjamin.consolvo?source=read_next_recirc-----68b2dede498f----0---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><div class="l ee"><img alt="Benjamin Consolvo" class="l eq bx xx xy cw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20-uWKiba-mLIUl2OQRF2OWw.jpg" width="20" height="20" loading="lazy"><div class="em bx l xx xy eo n ax ep"></div></div></a></div></div></div><div class="xz l"><div><div class="l" aria-hidden="false" aria-describedby="146" aria-labelledby="146"><a class="af ag ah ai aj ak al am an ao ap aq ar ih ab q" href="https://medium.com/@benjamin.consolvo?source=read_next_recirc-----68b2dede498f----0---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><p class="be b dx z ix iy iz ja jb jc jd je bj">Benjamin Consolvo</p></a></div></div></div><div class="xz l"><p class="be b dx z dw">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="147" aria-labelledby="147"><a class="af ag ah ai aj ak al am an ao ap aq ar ih ab q" href="https://medium.com/intel-analytics-software?source=read_next_recirc-----68b2dede498f----0---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><p class="be b dx z ix iy iz ja jb jc jd je bj">Intel Analytics Software</p></a></div></div></div></div><div class="ya l yb yc yd ye yf fk"><div class="yg yh yi yj yk yl ym yn"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/intel-analytics-software/automatic-speech-recognition-using-openai-whisper-without-a-gpu-9d316a93860a?source=read_next_recirc-----68b2dede498f----0---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><div title=""><h2 class="be gh yo yp yq yr ys yt yu yv yw yx nd yy yz za zb nh zc zd ze zf nl zg zh zi zj ix iz ja jc je bj">Automatic Speech Recognition using OpenAI Whisper without a GPU</h2></div><div class="zk l"><h3 class="be b if z ix zl iz ja zm jc je dw">Easy Step-by-Step Guide to English and French Transcription and Translation on CPUs</h3></div></a></div></div><span class="be b dx z dw"><div class="ht ab co ae"><div class="ab q"><span>Mar 13</span><div class=""><div class="ee zn dg ab q"><div class="eo tj zo ab q"><div class="aw dg di l cw"></div></div><a class="eo ll zo ab q" tabindex="-1" href="https://medium.com/intel-analytics-software/automatic-speech-recognition-using-openai-whisper-without-a-gpu-9d316a93860a?source=read_next_recirc-----68b2dede498f----0---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><div class="aw l"><div><div class="ab" aria-hidden="false" aria-describedby="216" aria-labelledby="216"><div class="ab q ee"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3.67 10.17l2.14 2.14c1.72 1.72 4.33 2.43 5.96.8a4.38 4.38 0 0 0 .76-5.38L10.7 4.25c-.35-.53-.85-1.22-1.33-.96-.5.26 0 1.56 0 1.56l.78 1.93-3.73-3.91C5.6 1.9 4.96 1.76 4.5 2.22c-.33.33-.26.85.48 1.6.5.5 1.89 1.95 1.89 1.95.17.18.08.49-.1.66-.09.1-.2.15-.34.16a.43.43 0 0 1-.31-.13l-2.8-2.87c-.35-.35-.8-.54-1.2-.15-.4.4-.27 1.06.11 1.44l2.69 2.67.06.06c.17.18.27.63.1.8-.2.2-.46.33-.69.28a.92.92 0 0 1-.44-.28S2.5 6.84 1.89 6.23c-.4-.4-.9-.33-1.23 0-.52.52.27 1.28 1.73 2.7.39.36.82.77 1.28 1.24zm8.47-7.22c.38-.3.95-.28 1.3.24l1.57 3a5 5 0 0 1-.48 5.24l-.03.04c-.21.27-.35.43-.74.61 1.38-1.85.96-3.47-.25-5.45l-1.57-2.75v-.04c-.02-.3-.04-.7.2-.9z" fill="#6B6B6B"></path></svg><span style="margin-left: 4px;">155</span></div></div></div></div><div class="aw l"><div><div class="ab" aria-hidden="false" aria-describedby="148" aria-labelledby="148"><div class="ab q ee"><svg width="16" height="16" viewBox="0 0 16 16" fill="#6B6B6B"><path d="M12.34 11.46A5.28 5.28 0 0 0 14 7.53C14 4.48 11.4 2 8.05 2 4.71 2 2 4.48 2 7.53c0 3.05 2.71 5.52 6.06 5.52.6 0 1.18-.08 1.76-.23.17.14.35.29.55.41.78.51 1.63.77 2.51.77.17 0 .3-.08.36-.22a.37.37 0 0 0-.03-.38 4.73 4.73 0 0 1-.86-1.96v.02z" fill="#6B6B6B"></path></svg><span style="margin-left: 4px;">3</span></div></div></div></div></a></div></div></div><div class="ab q zp zq"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="149" aria-labelledby="149"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al zr an ao ap im lr ls lt"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lu"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="zs l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="218" aria-labelledby="218"><button aria-label="More options" class="af ef ah ai aj ak al zr an ao ap im mb mc lo md"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></span><div class="j i d"><div class="rl bg rm lk"></div></div></div></div></div></div></div></div></article></div></div><div class="vp vq vr vs vt vu vv vw vx vy vz wa wb wc wd we wf wg wh wi wj"><div class="wk wl wm wn wo dy l"><article class="dy"><div class="dy pr l"><div class="bg dy"><div class="dy l"><div class="ee dy wp wq wr ws wt wu wv ww wx wy wz xa xb" role="link" data-href="https://medium.com/@speshiou/build-your-own-stable-diffusion-api-endpoint-1618f3aa5a28" tabindex="0"><div class="xc"><div aria-label="Build your own Stable Diffusion API endpoint"><div class="xe xf xg xh xi"><img alt="Build your own Stable Diffusion API endpoint" class="bg xj xk xl xm bw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20hRtN-ABxdH_RHX52w0iK3g.jpg" loading="lazy"></div></div></div><div class="xd ab ca cn"><div class="ab cn xn bg xo xp xq xr"><div class="xs xt xu xv xw ab q"><div class="pd l"><div><div class="l" aria-hidden="false" aria-describedby="151" aria-labelledby="151"><a tabindex="-1" href="https://medium.com/@speshiou?source=read_next_recirc-----68b2dede498f----1---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><div class="l ee"><img alt="speshiou" class="l eq bx xx xy cw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20_WV-xYZiUuvrhKw7rO1zdQ.png" width="20" height="20" loading="lazy"><div class="em bx l xx xy eo n ax ep"></div></div></a></div></div></div><div class="xz l"><div><div class="l" aria-hidden="false" aria-describedby="152" aria-labelledby="152"><a class="af ag ah ai aj ak al am an ao ap aq ar ih ab q" href="https://medium.com/@speshiou?source=read_next_recirc-----68b2dede498f----1---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><p class="be b dx z ix iy iz ja jb jc jd je bj">speshiou</p></a></div></div></div></div><div class="ya l yb yc yd ye yf fk"><div class="yg yh yi yj yk yl ym yn"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@speshiou/build-your-own-stable-diffusion-api-endpoint-1618f3aa5a28?source=read_next_recirc-----68b2dede498f----1---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><div title=""><h2 class="be gh yo yp yq yr ys yt yu yv yw yx nd yy yz za zb nh zc zd ze zf nl zg zh zi zj ix iz ja jc je bj">Build your own Stable Diffusion API endpoint</h2></div><div class="zk l"><h3 class="be b if z ix zl iz ja zm jc je dw">Creating
 your own SD API can be a complex task. In this article, will lead you 
through the process of establishing your own SD API</h3></div></a></div></div><span class="be b dx z dw"><div class="ht ab co ae"><div class="ab q"><span>Jan 6</span><div class=""><div class="ee zn dg ab q"><div class="eo tj zo ab q"><div class="aw dg di l cw"></div></div><a class="eo ll zo ab q" tabindex="-1" href="https://medium.com/@speshiou/build-your-own-stable-diffusion-api-endpoint-1618f3aa5a28?source=read_next_recirc-----68b2dede498f----1---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><div class="aw l"><div><div class="ab" aria-hidden="false" aria-describedby="219" aria-labelledby="219"><div class="ab q ee"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3.67 10.17l2.14 2.14c1.72 1.72 4.33 2.43 5.96.8a4.38 4.38 0 0 0 .76-5.38L10.7 4.25c-.35-.53-.85-1.22-1.33-.96-.5.26 0 1.56 0 1.56l.78 1.93-3.73-3.91C5.6 1.9 4.96 1.76 4.5 2.22c-.33.33-.26.85.48 1.6.5.5 1.89 1.95 1.89 1.95.17.18.08.49-.1.66-.09.1-.2.15-.34.16a.43.43 0 0 1-.31-.13l-2.8-2.87c-.35-.35-.8-.54-1.2-.15-.4.4-.27 1.06.11 1.44l2.69 2.67.06.06c.17.18.27.63.1.8-.2.2-.46.33-.69.28a.92.92 0 0 1-.44-.28S2.5 6.84 1.89 6.23c-.4-.4-.9-.33-1.23 0-.52.52.27 1.28 1.73 2.7.39.36.82.77 1.28 1.24zm8.47-7.22c.38-.3.95-.28 1.3.24l1.57 3a5 5 0 0 1-.48 5.24l-.03.04c-.21.27-.35.43-.74.61 1.38-1.85.96-3.47-.25-5.45l-1.57-2.75v-.04c-.02-.3-.04-.7.2-.9z" fill="#6B6B6B"></path></svg><span style="margin-left: 4px;">1</span></div></div></div></div></a></div></div></div><div class="ab q zp zq"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="153" aria-labelledby="153"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al zr an ao ap im lr ls lt"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lu"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="zs l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="220" aria-labelledby="220"><button aria-label="More options" class="af ef ah ai aj ak al zr an ao ap im mb mc lo md"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div></div></div><div class="rl bg rm aco"></div><h2 class="be rg if z gf bj">Lists</h2><div class="acp l"><div class="cm ab kn is va vb vc vd ve vf vg vh vi vj vk vl vm vn vo"><div class="vp vq vr vs vt vu vv vw vx vy vz wa wb wc wd we wf wg wh wi wj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" href="https://medium.com/@ben.putney/list/predictive-modeling-w-python-e3668ea008e1?source=read_next_recirc-----68b2dede498f--------------------------------" rel="noopener follow"><div class="acv acw ix ab ip ee"><div class="ee xj acr bw acs"><div class="xj ht ix l"><img alt="" class="" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%20r4yjMpEmqzHCUvWC.jpg" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="ee xj acr bw ko act"><div class="xj ht ix l"><img alt="" class="" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20bv2KUVNLi2sFNjBTdoBmWw.png" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="ee xj bw ib acu"><div class="xj ht ix l"><img alt="" class="" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%20zsngbTOmFCy6sUCx.jpg" width="48" height="48" loading="lazy" role="presentation"></div></div></div><div class="aw l"><h2 class="be rg if z ix zl iz ja zm jc je gf bj">Predictive Modeling w/ Python</h2><div class="be b dx z dw ab acq">20 stories<span class="ii l" aria-hidden="true"><span class="be b bf z dw">·</span></span>1213 saves</div></div></a></div><div class="vp vq vr vs vt vu vv vw vx vy vz wa wb wc wd we wf wg wh wi wj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" href="https://medium.com/@AMGAS14/list/natural-language-processing-0a856388a93a?source=read_next_recirc-----68b2dede498f--------------------------------" rel="noopener follow"><div class="acv acw ix ab ip ee"><div class="ee xj acr bw acs"><div class="xj ht ix l"><img alt="" class="" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20weT34uhEIuLzpwhygQrt5A.png" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="ee xj acr bw ko act"><div class="xj ht ix l"><img alt="" class="" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%20oJqRrsccoq9YmsRW.jpg" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="ee xj bw ib acu"><div class="xj ht ix l"><img alt="" class="" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%20wpsYTsTeC2A_rQ-7.jpg" width="48" height="48" loading="lazy" role="presentation"></div></div></div><div class="aw l"><h2 class="be rg if z ix zl iz ja zm jc je gf bj">Natural Language Processing</h2><div class="be b dx z dw ab acq">1465 stories<span class="ii l" aria-hidden="true"><span class="be b bf z dw">·</span></span>978 saves</div></div></a></div><div class="vp vq vr vs vt vu vv vw vx vy vz wa wb wc wd we wf wg wh wi wj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" href="https://destingong.medium.com/list/practical-guides-to-machine-learning-a877c2a39884?source=read_next_recirc-----68b2dede498f--------------------------------" rel="noopener follow"><div class="acv acw ix ab ip ee"><div class="ee xj acr bw acs"><div class="xj ht ix l"><img alt="Principal Component Analysis for ML" class="" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20swd_PY6vTCyPnsgBYoFZfA.png" width="48" height="48" loading="lazy"></div></div><div class="ee xj acr bw ko act"><div class="xj ht ix l"><img alt="Time Series Analysis" class="" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%208sSAHftNwd_RNJ3k4VA0pA.png" width="48" height="48" loading="lazy"></div></div><div class="ee xj bw ib acu"><div class="xj ht ix l"><img alt="deep learning cheatsheet for beginner" class="" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20uNyD4yNMH-DnOel1wzxOOA.png" width="48" height="48" loading="lazy"></div></div></div><div class="aw l"><h2 class="be rg if z ix zl iz ja zm jc je gf bj">Practical Guides to Machine Learning</h2><div class="be b dx z dw ab acq">10 stories<span class="ii l" aria-hidden="true"><span class="be b bf z dw">·</span></span>1462 saves</div></div></a></div><div class="vp vq vr vs vt vu vv vw vx vy vz wa wb wc wd we wf wg wh wi wj"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" href="https://medium.com/@grexe/list/data-science-and-ai-35d21381d956?source=read_next_recirc-----68b2dede498f--------------------------------" rel="noopener follow"><div class="acv acw ix ab ip ee"><div class="ee xj acr bw acs"><div class="xj ht ix l"><img alt="" class="" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20Fwpkf8H5PwNrzSzMYUFjjA.png" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="ee xj acr bw ko act"><div class="xj ht ix l"><img alt="" class="" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20G49cai7vIuhFeSwb4LCuSQ.jpg" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="ee xj bw ib acu"><div class="xj ht ix l"><img alt="" class="" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20HlJ2e41GVVzzjWYiX0dU1g.png" width="48" height="48" loading="lazy" role="presentation"></div></div></div><div class="aw l"><h2 class="be rg if z ix zl iz ja zm jc je gf bj">data science and AI</h2><div class="be b dx z dw ab acq">40 stories<span class="ii l" aria-hidden="true"><span class="be b bf z dw">·</span></span>163 saves</div></div></a></div></div></div><div class="rl bg rm abq dj abs dk acx acy acz ada adb adc"></div><div class="uz ab kn is va vb vc vd ve vf vg vh vi vj vk vl vm vn vo"><div class="vp vq vr vs vt vu vv vw vx vy vz wa wb wc wd we wf wg wh wi wj"><div class="wk wl wm wn wo dy l"><article class="dy"><div class="dy pr l"><div class="bg dy"><div class="dy l"><div class="ee dy wp wq wr ws wt wu wv ww wx wy wz xa xb" role="link" data-href="https://medium.com/@isaiahlove085/create-an-ai-voice-assistant-a95a9a2e79a9" tabindex="0"><div class="xc"><div aria-label="Create An AI Voice Assistant Using Python"><div class="xe xf xg xh xi"><img alt="Create An AI Voice Assistant Using Python" class="bg xj xk xl xm bw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20VkkCme8tkb5ah3ugjBkcnQ.png" loading="lazy"></div></div></div><div class="xd ab ca cn"><div class="ab cn xn bg xo xp xq xr"><div class="xs xt xu xv xw ab q"><div class="pd l"><div><div class="l" aria-hidden="false" aria-describedby="155" aria-labelledby="155"><a tabindex="-1" href="https://medium.com/@isaiahlove085?source=read_next_recirc-----68b2dede498f----0---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><div class="l ee"><img alt="Isaiah Love" class="l eq bx xx xy cw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%20q9hYsup8DcjaFqi7.jpg" width="20" height="20" loading="lazy"><div class="em bx l xx xy eo n ax ep"></div></div></a></div></div></div><div class="xz l"><div><div class="l" aria-hidden="false" aria-describedby="156" aria-labelledby="156"><a class="af ag ah ai aj ak al am an ao ap aq ar ih ab q" href="https://medium.com/@isaiahlove085?source=read_next_recirc-----68b2dede498f----0---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><p class="be b dx z ix iy iz ja jb jc jd je bj">Isaiah Love</p></a></div></div></div></div><div class="ya l yb yc yd ye yf fk"><div class="yg yh yi yj yk yl ym yn"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@isaiahlove085/create-an-ai-voice-assistant-a95a9a2e79a9?source=read_next_recirc-----68b2dede498f----0---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><div title=""><h2 class="be gh yo yp yq yr ys yt yu yv yw yx nd yy yz za zb nh zc zd ze zf nl zg zh zi zj ix iz ja jc je bj">Create An AI Voice Assistant Using Python</h2></div><div class="zk l"><h3 class="be b if z ix zl iz ja zm jc je dw">Welcome
 to the fascinating world of AI Voice Assistants! In this article, I’ll 
guide you through the exciting process of creating your very…</h3></div></a></div></div><span class="be b dx z dw"><div class="ht ab co ae"><div class="ab q"><span>Nov 30, 2023</span><div class=""><div class="ee zn dg ab q"><div class="eo tj zo ab q"><div class="aw dg di l cw"></div></div><a class="eo ll zo ab q" tabindex="-1" href="https://medium.com/@isaiahlove085/create-an-ai-voice-assistant-a95a9a2e79a9?source=read_next_recirc-----68b2dede498f----0---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><div class="aw l"><div><div class="ab" aria-hidden="false" aria-describedby="221" aria-labelledby="221"><div class="ab q ee"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3.67 10.17l2.14 2.14c1.72 1.72 4.33 2.43 5.96.8a4.38 4.38 0 0 0 .76-5.38L10.7 4.25c-.35-.53-.85-1.22-1.33-.96-.5.26 0 1.56 0 1.56l.78 1.93-3.73-3.91C5.6 1.9 4.96 1.76 4.5 2.22c-.33.33-.26.85.48 1.6.5.5 1.89 1.95 1.89 1.95.17.18.08.49-.1.66-.09.1-.2.15-.34.16a.43.43 0 0 1-.31-.13l-2.8-2.87c-.35-.35-.8-.54-1.2-.15-.4.4-.27 1.06.11 1.44l2.69 2.67.06.06c.17.18.27.63.1.8-.2.2-.46.33-.69.28a.92.92 0 0 1-.44-.28S2.5 6.84 1.89 6.23c-.4-.4-.9-.33-1.23 0-.52.52.27 1.28 1.73 2.7.39.36.82.77 1.28 1.24zm8.47-7.22c.38-.3.95-.28 1.3.24l1.57 3a5 5 0 0 1-.48 5.24l-.03.04c-.21.27-.35.43-.74.61 1.38-1.85.96-3.47-.25-5.45l-1.57-2.75v-.04c-.02-.3-.04-.7.2-.9z" fill="#6B6B6B"></path></svg><span style="margin-left: 4px;">106</span></div></div></div></div><div class="aw l"><div><div class="ab" aria-hidden="false" aria-describedby="157" aria-labelledby="157"><div class="ab q ee"><svg width="16" height="16" viewBox="0 0 16 16" fill="#6B6B6B"><path d="M12.34 11.46A5.28 5.28 0 0 0 14 7.53C14 4.48 11.4 2 8.05 2 4.71 2 2 4.48 2 7.53c0 3.05 2.71 5.52 6.06 5.52.6 0 1.18-.08 1.76-.23.17.14.35.29.55.41.78.51 1.63.77 2.51.77.17 0 .3-.08.36-.22a.37.37 0 0 0-.03-.38 4.73 4.73 0 0 1-.86-1.96v.02z" fill="#6B6B6B"></path></svg><span style="margin-left: 4px;">1</span></div></div></div></div></a></div></div></div><div class="ab q zp zq"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="158" aria-labelledby="158"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al zr an ao ap im lr ls lt"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lu"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="zs l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="223" aria-labelledby="223"><button aria-label="More options" class="af ef ah ai aj ak al zr an ao ap im mb mc lo md"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></span><div class="j i d"><div class="rl bg rm lk"></div></div></div></div></div></div></div></div></article></div></div><div class="vp vq vr vs vt vu vv vw vx vy vz wa wb wc wd we wf wg wh wi wj"><div class="wk wl wm wn wo dy l"><article class="dy"><div class="dy pr l"><div class="bg dy"><div class="dy l"><div class="ee dy wp wq wr ws wt wu wv ww wx wy wz xa xb" role="link" data-href="https://towardsdatascience.com/meet-the-nicegui-your-soon-to-be-favorite-python-ui-library-fb69f14bb0ac" tabindex="0"><div class="xc"><div aria-label="Meet the NiceGUI: Your Soon-to-be Favorite Python UI Library"><div class="xe xf xg xh xi"><img alt="Meet the NiceGUI: Your Soon-to-be Favorite Python UI Library" class="bg xj xk xl xm bw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%203Onb4V0s12hVk4gQHy13VA.jpg" loading="lazy"></div></div></div><div class="xd ab ca cn"><div class="ab cn xn bg xo xp xq xr"><div class="xs xt xu xv xw ab q"><div class="pd l"><div><div class="l" aria-hidden="false" aria-describedby="160" aria-labelledby="160"><a tabindex="-1" href="https://medium.com/@CVxTz?source=read_next_recirc-----68b2dede498f----1---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><div class="l ee"><img alt="Youness Mansar" class="l eq bx xx xy cw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20RtTih4vs60WnJcUVT0K1fw.jpg" width="20" height="20" loading="lazy"><div class="em bx l xx xy eo n ax ep"></div></div></a></div></div></div><div class="xz l"><div><div class="l" aria-hidden="false" aria-describedby="161" aria-labelledby="161"><a class="af ag ah ai aj ak al am an ao ap aq ar ih ab q" href="https://medium.com/@CVxTz?source=read_next_recirc-----68b2dede498f----1---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><p class="be b dx z ix iy iz ja jb jc jd je bj">Youness Mansar</p></a></div></div></div><div class="xz l"><p class="be b dx z dw">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="162" aria-labelledby="162"><a class="af ag ah ai aj ak al am an ao ap aq ar ih ab q" href="https://towardsdatascience.com/?source=read_next_recirc-----68b2dede498f----1---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><p class="be b dx z ix iy iz ja jb jc jd je bj">Towards Data Science</p></a></div></div></div></div><div class="ya l yb yc yd ye yf fk"><div class="yg yh yi yj yk yl ym yn"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/meet-the-nicegui-your-soon-to-be-favorite-python-ui-library-fb69f14bb0ac?source=read_next_recirc-----68b2dede498f----1---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------"><div title=""><h2 class="be gh yo yp yq yr ys yt yu yv yw yx nd yy yz za zb nh zc zd ze zf nl zg zh zi zj ix iz ja jc je bj">Meet the NiceGUI: Your Soon-to-be Favorite Python UI Library</h2></div><div class="zk l"><h3 class="be b if z ix zl iz ja zm jc je dw">Build custom web apps easily and quickly</h3></div></a></div></div><span class="be b dx z dw"><div class="ht ab co ae"><div class="ab q"><span>Apr 16</span><div class=""><div class="ee zn dg ab q"><div class="eo tj zo ab q"><div class="aw dg di l cw"></div></div><a class="eo ll zo ab q" tabindex="-1" rel="noopener follow" href="https://towardsdatascience.com/meet-the-nicegui-your-soon-to-be-favorite-python-ui-library-fb69f14bb0ac?source=read_next_recirc-----68b2dede498f----1---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------"><div class="aw l"><div><div class="ab" aria-hidden="false" aria-describedby="224" aria-labelledby="224"><div class="ab q ee"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3.67 10.17l2.14 2.14c1.72 1.72 4.33 2.43 5.96.8a4.38 4.38 0 0 0 .76-5.38L10.7 4.25c-.35-.53-.85-1.22-1.33-.96-.5.26 0 1.56 0 1.56l.78 1.93-3.73-3.91C5.6 1.9 4.96 1.76 4.5 2.22c-.33.33-.26.85.48 1.6.5.5 1.89 1.95 1.89 1.95.17.18.08.49-.1.66-.09.1-.2.15-.34.16a.43.43 0 0 1-.31-.13l-2.8-2.87c-.35-.35-.8-.54-1.2-.15-.4.4-.27 1.06.11 1.44l2.69 2.67.06.06c.17.18.27.63.1.8-.2.2-.46.33-.69.28a.92.92 0 0 1-.44-.28S2.5 6.84 1.89 6.23c-.4-.4-.9-.33-1.23 0-.52.52.27 1.28 1.73 2.7.39.36.82.77 1.28 1.24zm8.47-7.22c.38-.3.95-.28 1.3.24l1.57 3a5 5 0 0 1-.48 5.24l-.03.04c-.21.27-.35.43-.74.61 1.38-1.85.96-3.47-.25-5.45l-1.57-2.75v-.04c-.02-.3-.04-.7.2-.9z" fill="#6B6B6B"></path></svg><span style="margin-left: 4px;">1.5K</span></div></div></div></div><div class="aw l"><div><div class="ab" aria-hidden="false" aria-describedby="163" aria-labelledby="163"><div class="ab q ee"><svg width="16" height="16" viewBox="0 0 16 16" fill="#6B6B6B"><path d="M12.34 11.46A5.28 5.28 0 0 0 14 7.53C14 4.48 11.4 2 8.05 2 4.71 2 2 4.48 2 7.53c0 3.05 2.71 5.52 6.06 5.52.6 0 1.18-.08 1.76-.23.17.14.35.29.55.41.78.51 1.63.77 2.51.77.17 0 .3-.08.36-.22a.37.37 0 0 0-.03-.38 4.73 4.73 0 0 1-.86-1.96v.02z" fill="#6B6B6B"></path></svg><span style="margin-left: 4px;">8</span></div></div></div></div></a></div></div></div><div class="ab q zp zq"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="164" aria-labelledby="164"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al zr an ao ap im lr ls lt"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lu"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="zs l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="226" aria-labelledby="226"><button aria-label="More options" class="af ef ah ai aj ak al zr an ao ap im mb mc lo md"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></span><div class="j i d"><div class="rl bg rm lk"></div></div></div></div></div></div></div></div></article></div></div><div class="vp vq vr vs vt vu vv vw vx vy vz wa wb wc wd we wf wg wh wi wj"><div class="wk wl wm wn wo dy l"><article class="dy"><div class="dy pr l"><div class="bg dy"><div class="dy l"><div class="ee dy wp wq wr ws wt wu wv ww wx wy wz xa xb" role="link" data-href="https://medium.com/bitgrit-data-science-publication/a-roadmap-to-learn-ai-in-2024-cc30c6aa6e16" tabindex="0"><div class="xc"><div aria-label="Roadmap to Learn AI in 2024"><div class="xe xf xg xh xi"><img alt="Roadmap to Learn AI in 2024" class="bg xj xk xl xm bw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20TQlEMeYwwWc38Wqm7EfCTg.png" loading="lazy"></div></div></div><div class="xd ab ca cn"><div class="ab cn xn bg xo xp xq xr"><div class="xs xt xu xv xw ab q"><div class="pd l"><div><div class="l" aria-hidden="false" aria-describedby="166" aria-labelledby="166"><a tabindex="-1" href="https://benedictxneo.medium.com/?source=read_next_recirc-----68b2dede498f----2---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><div class="l ee"><img alt="Benedict Neo" class="l eq bx xx xy cw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%200-N4JrXpZG1KJfIrAutd3A.png" width="20" height="20" loading="lazy"><div class="em bx l xx xy eo n ax ep"></div></div></a></div></div></div><div class="xz l"><div><div class="l" aria-hidden="false" aria-describedby="167" aria-labelledby="167"><a class="af ag ah ai aj ak al am an ao ap aq ar ih ab q" href="https://benedictxneo.medium.com/?source=read_next_recirc-----68b2dede498f----2---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><p class="be b dx z ix iy iz ja jb jc jd je bj">Benedict Neo</p></a></div></div></div><div class="xz l"><p class="be b dx z dw">in</p></div><div class="l"><div><div class="l" aria-hidden="false" aria-describedby="168" aria-labelledby="168"><a class="af ag ah ai aj ak al am an ao ap aq ar ih ab q" href="https://medium.com/bitgrit-data-science-publication?source=read_next_recirc-----68b2dede498f----2---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><p class="be b dx z ix iy iz ja jb jc jd je bj">bitgrit Data Science Publication</p></a></div></div></div></div><div class="ya l yb yc yd ye yf fk"><div class="yg yh yi yj yk yl ym yn"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/bitgrit-data-science-publication/a-roadmap-to-learn-ai-in-2024-cc30c6aa6e16?source=read_next_recirc-----68b2dede498f----2---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><div title=""><h2 class="be gh yo yp yq yr ys yt yu yv yw yx nd yy yz za zb nh zc zd ze zf nl zg zh zi zj ix iz ja jc je bj">Roadmap to Learn AI in 2024</h2></div><div class="zk l"><h3 class="be b if z ix zl iz ja zm jc je dw">A free curriculum for hackers and programmers to learn AI</h3></div></a></div></div><span class="be b dx z dw"><div class="ht ab co ae"><div class="ab q"><span>Mar 11</span><div class=""><div class="ee zn dg ab q"><div class="eo tj zo ab q"><div class="aw dg di l cw"></div></div><a class="eo ll zo ab q" tabindex="-1" href="https://medium.com/bitgrit-data-science-publication/a-roadmap-to-learn-ai-in-2024-cc30c6aa6e16?source=read_next_recirc-----68b2dede498f----2---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><div class="aw l"><div><div class="ab" aria-hidden="false" aria-describedby="227" aria-labelledby="227"><div class="ab q ee"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3.67 10.17l2.14 2.14c1.72 1.72 4.33 2.43 5.96.8a4.38 4.38 0 0 0 .76-5.38L10.7 4.25c-.35-.53-.85-1.22-1.33-.96-.5.26 0 1.56 0 1.56l.78 1.93-3.73-3.91C5.6 1.9 4.96 1.76 4.5 2.22c-.33.33-.26.85.48 1.6.5.5 1.89 1.95 1.89 1.95.17.18.08.49-.1.66-.09.1-.2.15-.34.16a.43.43 0 0 1-.31-.13l-2.8-2.87c-.35-.35-.8-.54-1.2-.15-.4.4-.27 1.06.11 1.44l2.69 2.67.06.06c.17.18.27.63.1.8-.2.2-.46.33-.69.28a.92.92 0 0 1-.44-.28S2.5 6.84 1.89 6.23c-.4-.4-.9-.33-1.23 0-.52.52.27 1.28 1.73 2.7.39.36.82.77 1.28 1.24zm8.47-7.22c.38-.3.95-.28 1.3.24l1.57 3a5 5 0 0 1-.48 5.24l-.03.04c-.21.27-.35.43-.74.61 1.38-1.85.96-3.47-.25-5.45l-1.57-2.75v-.04c-.02-.3-.04-.7.2-.9z" fill="#6B6B6B"></path></svg><span style="margin-left: 4px;">11.8K</span></div></div></div></div><div class="aw l"><div><div class="ab" aria-hidden="false" aria-describedby="169" aria-labelledby="169"><div class="ab q ee"><svg width="16" height="16" viewBox="0 0 16 16" fill="#6B6B6B"><path d="M12.34 11.46A5.28 5.28 0 0 0 14 7.53C14 4.48 11.4 2 8.05 2 4.71 2 2 4.48 2 7.53c0 3.05 2.71 5.52 6.06 5.52.6 0 1.18-.08 1.76-.23.17.14.35.29.55.41.78.51 1.63.77 2.51.77.17 0 .3-.08.36-.22a.37.37 0 0 0-.03-.38 4.73 4.73 0 0 1-.86-1.96v.02z" fill="#6B6B6B"></path></svg><span style="margin-left: 4px;">129</span></div></div></div></div></a></div></div></div><div class="ab q zp zq"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="170" aria-labelledby="170"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al zr an ao ap im lr ls lt"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lu"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="zs l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="229" aria-labelledby="229"><button aria-label="More options" class="af ef ah ai aj ak al zr an ao ap im mb mc lo md"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></span><div class="j i d"><div class="rl bg rm lk"></div></div></div></div></div></div></div></div></article></div></div><div class="vp vq vr vs vt vu vv vw vx vy vz wa wb wc wd we wf wg wh wi wj"><div class="wk wl wm wn wo dy l"><article class="dy"><div class="dy pr l"><div class="bg dy"><div class="dy l"><div class="ee dy wp wq wr ws wt wu wv ww wx wy wz xa xb" role="link" data-href="https://billtcheng2013.medium.com/faster-audio-transcribing-with-openai-whisper-and-huggingface-transformers-dc088243803d" tabindex="0"><div class="xc"><div aria-label="Faster Audio Transcribing with OpenAI Whisper and Huggingface Transformers"><div class="xe xf xg xh xi"><img alt="Faster Audio Transcribing with OpenAI Whisper and Huggingface Transformers" class="bg xj xk xl xm bw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1%20yuVzMhCJyDENbyhwAsrkwA.png" loading="lazy"></div></div></div><div class="xd ab ca cn"><div class="ab cn xn bg xo xp xq xr"><div class="xs xt xu xv xw ab q"><div class="pd l"><div><div class="l" aria-hidden="false" aria-describedby="172" aria-labelledby="172"><a tabindex="-1" href="https://billtcheng2013.medium.com/?source=read_next_recirc-----68b2dede498f----3---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><div class="l ee"><img alt="Xin Cheng" class="l eq bx xx xy cw" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/0%20d-iAojaOuqUdM0Z-.png" width="20" height="20" loading="lazy"><div class="em bx l xx xy eo n ax ep"></div></div></a></div></div></div><div class="xz l"><div><div class="l" aria-hidden="false" aria-describedby="173" aria-labelledby="173"><a class="af ag ah ai aj ak al am an ao ap aq ar ih ab q" href="https://billtcheng2013.medium.com/?source=read_next_recirc-----68b2dede498f----3---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><p class="be b dx z ix iy iz ja jb jc jd je bj">Xin Cheng</p></a></div></div></div></div><div class="ya l yb yc yd ye yf fk"><div class="yg yh yi yj yk yl ym yn"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://billtcheng2013.medium.com/faster-audio-transcribing-with-openai-whisper-and-huggingface-transformers-dc088243803d?source=read_next_recirc-----68b2dede498f----3---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><div title="Faster Audio Transcribing with OpenAI Whisper and Huggingface Transformers"><h2 class="be gh yo yp yq yr ys yt yu yv yw yx nd yy yz za zb nh zc zd ze zf nl zg zh zi zj ix iz ja jc je bj">Faster Audio Transcribing with OpenAI Whisper and Huggingface Transformers</h2></div><div class="zk l"><h3 class="be b if z ix zl iz ja zm jc je dw">Automatic speech recognition at scale</h3></div></a></div></div><span class="be b dx z dw"><div class="ht ab co ae"><div class="ab q"><span>Nov 22, 2023</span><div class=""><div class="ee zn dg ab q"><div class="eo tj zo ab q"><div class="aw dg di l cw"></div></div><a class="eo ll zo ab q" tabindex="-1" href="https://billtcheng2013.medium.com/faster-audio-transcribing-with-openai-whisper-and-huggingface-transformers-dc088243803d?source=read_next_recirc-----68b2dede498f----3---------------------f506309a_cda9_49a6_aff5_0384362d5c86-------" rel="noopener follow"><div class="aw l"><div><div class="ab" aria-hidden="false" aria-describedby="203" aria-labelledby="203"><div class="ab q ee"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3.67 10.17l2.14 2.14c1.72 1.72 4.33 2.43 5.96.8a4.38 4.38 0 0 0 .76-5.38L10.7 4.25c-.35-.53-.85-1.22-1.33-.96-.5.26 0 1.56 0 1.56l.78 1.93-3.73-3.91C5.6 1.9 4.96 1.76 4.5 2.22c-.33.33-.26.85.48 1.6.5.5 1.89 1.95 1.89 1.95.17.18.08.49-.1.66-.09.1-.2.15-.34.16a.43.43 0 0 1-.31-.13l-2.8-2.87c-.35-.35-.8-.54-1.2-.15-.4.4-.27 1.06.11 1.44l2.69 2.67.06.06c.17.18.27.63.1.8-.2.2-.46.33-.69.28a.92.92 0 0 1-.44-.28S2.5 6.84 1.89 6.23c-.4-.4-.9-.33-1.23 0-.52.52.27 1.28 1.73 2.7.39.36.82.77 1.28 1.24zm8.47-7.22c.38-.3.95-.28 1.3.24l1.57 3a5 5 0 0 1-.48 5.24l-.03.04c-.21.27-.35.43-.74.61 1.38-1.85.96-3.47-.25-5.45l-1.57-2.75v-.04c-.02-.3-.04-.7.2-.9z" fill="#6B6B6B"></path></svg><span style="margin-left: 4px;">61</span></div></div></div></div></a></div></div></div><div class="ab q zp zq"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="174" aria-labelledby="174"><div class="bl" aria-hidden="false"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af ef ah ai aj ak al zr an ao ap im lr ls lt"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" class="lu"><path d="M17.5 1.25a.5.5 0 0 1 1 0v2.5H21a.5.5 0 0 1 0 1h-2.5v2.5a.5.5 0 0 1-1 0v-2.5H15a.5.5 0 0 1 0-1h2.5v-2.5zm-11 4.5a1 1 0 0 1 1-1H11a.5.5 0 0 0 0-1H7.5a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V5.75z" fill="#000"></path></svg></button></div></div></div></div><div class="zs l"><div class="bl" aria-hidden="false"><div class="bl" aria-hidden="false"><div><div class="bl" aria-hidden="false" aria-describedby="204" aria-labelledby="204"><button aria-label="More options" class="af ef ah ai aj ak al zr an ao ap im mb mc lo md"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.39 12c0 .55.2 1.02.59 1.41.39.4.86.59 1.4.59.56 0 1.03-.2 1.42-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.6-1.41A1.93 1.93 0 0 0 6.4 10c-.55 0-1.02.2-1.41.59-.4.39-.6.86-.6 1.41zM10 12c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.54 0 1.02-.2 1.4-.59.4-.39.6-.86.6-1.41 0-.55-.2-1.02-.6-1.41a1.93 1.93 0 0 0-1.4-.59c-.55 0-1.04.2-1.42.59-.4.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.57 1.41.4.4.88.59 1.43.59.57 0 1.04-.2 1.43-.59.39-.39.57-.86.57-1.41 0-.55-.2-1.02-.57-1.41A1.93 1.93 0 0 0 17.6 10c-.55 0-1.04.2-1.43.59-.38.39-.57.86-.57 1.41z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></span></div></div></div></div></div></div></article></div></div></div><div class="rl bg rm dj dk zx zy zz"></div><a class="be b bf z bj pe abd abe abf uw ln abg us qy im abh abi abj rb abk abl abm abn abo rd re eq bl om oh" href="https://medium.com/?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><div class="l oh">See more recommendations</div></a></div></div></div><div class="h k j"><div class="rl bg rm rn"></div><div class="ab ca"><div class="ch bg ew ex ey ez"><div class="ro ab kn is"><div class="rp rq l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://help.medium.com/hc/en-us?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><p class="be b dx z dw">Help</p></a></div><div class="rp rq l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.statuspage.io/?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><p class="be b dx z dw">Status</p></a></div><div class="rp rq l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/about?autoplay=1&amp;source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><p class="be b dx z dw">About</p></a></div><div class="rp rq l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><p class="be b dx z dw">Careers</p></a></div><div class="rp rq l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="mailto:pressinquiries@medium.com?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><p class="be b dx z dw">Press</p></a></div><div class="rp rq l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://blog.medium.com/?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><p class="be b dx z dw">Blog</p></a></div><div class="rp rq l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><p class="be b dx z dw">Privacy</p></a></div><div class="rp rq l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><p class="be b dx z dw">Terms</p></a></div><div class="rp rq l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://speechify.com/medium?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><p class="be b dx z dw">Text to speech</p></a></div><div class="rp l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/business?source=post_page-----68b2dede498f--------------------------------" rel="noopener follow"><p class="be b dx z dw">Teams</p></a></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20240523-150943-951ed0cb8f"</script><script>window.__GRAPHQL_URI__ = "https://towardsdatascience.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"cache":{"experimentGroupSet":true,"reason":"User is logged in","group":"disabled","tags":["group-edgeCachePosts","post-68b2dede498f","user-e7f791e64e83","collection-7f60cf5620c9"],"serverVariantState":"","middlewareEnabled":true,"cacheStatus":"DYNAMIC","shouldUseCache":false,"vary":[],"updatedPostPreviewsEnabled":false,"lohpExperimentEnabled":"control"},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":true,"routingEntity":{"type":"COLLECTION","id":"7f60cf5620c9","explicit":true},"viewerIsBot":false},"debug":{"requestId":"c85f25f2-a6d8-43e2-bc12-13dd94656130","hybridDevServices":[],"originalSpanCarrier":{"ot-tracer-spanid":"09c96d5c752a3970","ot-tracer-traceid":"78e6fbd3dcb34432","ot-tracer-sampled":"true"}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Ftowardsdatascience.com\u002Fspeaker-differentiation-using-deep-learning-68b2dede498f","host":"towardsdatascience.com","hostname":"towardsdatascience.com","referrer":"https:\u002F\u002Fwww.google.com\u002F","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false},"config":{"nodeEnv":"production","version":"main-20240523-150943-951ed0cb8f","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","recaptchaEnterpriseKeyId":"6Le-uGgpAAAAAPprRaokM8AKthQ9KNGdoxaGUvVp","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20240523-150943-951ed0cb8f","commit":"951ed0cb8fbec5d4de5cce21294bc2dae3c055cf"}},"datacenter":"us"},"googleAnalyticsCode":"G-7JY7T788PK","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*kFrc4tBFM_tCis-2Ic87WA.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyV2":"e8a5e126-792b-4ee6-8fba-d574c1b02fc5","monthlyWithTrial":"d5ee3dbe3db8","monthlyPremium":"fa741a9b47a2","yearly":"a40ad4a43185","yearlyV2":"3815d7d6-b8ca-4224-9b8c-182f9047866e","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","yearlyPremium":"e21bd2c12166","monthlyOneYearFree":"e6c0637a-2bad-4171-ab4f-3c268633d83c","monthly25PercentOffFirstYear":"235ecc62-0cdb-49ae-9378-726cd21c504b","monthly20PercentOffFirstYear":"ba518864-9c13-4a99-91ca-411bf0cac756","monthly15PercentOffFirstYear":"594c029b-9f89-43d5-88f8-8173af4e070e","monthly10PercentOffFirstYear":"c6c7bc9a-40f2-4b51-8126-e28511d5bdb0","monthlyForStudents":"629ebe51-da7d-41fd-8293-34cd2f2030a8","yearlyOneYearFree":"78ba7be9-0d9f-4ece-aa3e-b54b826f2bf1","yearly25PercentOffFirstYear":"2dbb010d-bb8f-4eeb-ad5c-a08509f42d34","yearly20PercentOffFirstYear":"47565488-435b-47f8-bf93-40d5fbe0ebc8","yearly15PercentOffFirstYear":"8259809b-0881-47d9-acf7-6c001c7f720f","yearly10PercentOffFirstYear":"9dd694fb-96e1-472c-8d9e-3c868d5c1506","yearlyForStudents":"e29345ef-ab1c-4234-95c5-70e50fe6bc23","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","q8qw":"usd","d9y6":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks","catalogId":"c7bc6e1ee00f"}},"session":{"xsrf":"83e430f370ee"}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","variantFlags":[{"__typename":"VariantFlag","name":"enable_cache_less_following_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_play_purchase_on_backend","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mps_pp_writer_stats","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_sprig","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_switch_plan_premium_tier","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_dynamic_programming_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_iceland_forced_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_lists_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_offline_reading","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_rex_anno","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_user_onboarding_emails_flow","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"enable_sharer_validate_post_share_key","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipping_v0_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lo_homepage","valueType":{"__typename":"VariantFlagString","value":"group_3"}},{"__typename":"VariantFlag","name":"enable_mastodon_avatar_upload","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_client","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_offline_reading","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_auto_follow_on_subscribe","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_verified_author","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_friend_links_creation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_maim_the_meter","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_for_members","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_topic_portals","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_reading_history","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_new_push_notification_endpoint","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_access","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_marketing_emails","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_friend_links_postpage_banners","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_plan","valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"}},{"__typename":"VariantFlag","name":"enable_ios_easy_resubscribe","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_legacy_feed_in_iceland","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_speechify_widget","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_susi_redesign_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_friend_links_creation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tribute_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_post_referrers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_premium_plan","valueType":{"__typename":"VariantFlagString","value":"4a442ace1476"}},{"__typename":"VariantFlag","name":"enable_creator_welcome_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_expired_membership_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_apple_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_google_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_deprecate_legacy_providers_v3","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"price_smoke_test_yearly","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"enable_android_miro_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_io","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_server_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_social_share_sheet","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"can_send_tips_v0","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_import","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_homepage","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"crm_send_contact_to_sendgrid","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_explicit_signals_updated_post_previews","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_members_only_audio","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"can_receive_tips_v0","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_archive_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_response_markup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"reader_fair_distribution_non_qp","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_two_hour_refresh","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_friend_links_postpage_banners","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"browsable_stream_config_bucket","valueType":{"__typename":"VariantFlagString","value":"curated-topics"}},{"__typename":"VariantFlag","name":"enable_braintree_paypal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_dynamic_paywall_aspiriational","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_editor_new_publishing_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_pub_follower_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_app_flirty_thirty","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_remove_twitter_onboarding_step","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_autorefresh","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_sharer_create_post_share_key","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"coronavirus_topic_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_footer_app_buttons","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rito_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_dynamic_aspirational_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signin_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"glyph_font_set","valueType":{"__typename":"VariantFlagString","value":"m2-unbound-source-serif-pro"}},{"__typename":"VariantFlag","name":"rex_generator_max_candidates","valueType":{"__typename":"VariantFlagNumber"}},{"__typename":"VariantFlag","name":"ios_display_paywall_after_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_monthly_premium_plan","valueType":{"__typename":"VariantFlagString","value":"12a660186432"}},{"__typename":"VariantFlag","name":"enable_entities_to_follow_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"price_smoke_test_monthly","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"android_rating_prompt_stories_read_threshold","valueType":{"__typename":"VariantFlagNumber"}},{"__typename":"VariantFlag","name":"enable_braintree_trial_membership","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_premium_tier_badge","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_syntax_highlight","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_diversification_rex","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_aggregator_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_bg_post_post","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_eventstats_event_processing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_user_follows","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"onboarding_tags_from_top_views","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_partner_program_enrollment","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_cards","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_for_members_username_selection","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_verifications_service","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"reengagement_notification_duration","valueType":{"__typename":"VariantFlagNumber"}},{"__typename":"VariantFlag","name":"signup_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"skip_fs_cache_user_vals","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_monthly_plan","valueType":{"__typename":"VariantFlagString","value":"60e220181034"}},{"__typename":"VariantFlag","name":"enable_author_cards_byline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_continue_this_thread","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_medium2_kbfd","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipping_v0_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"textshots_userid","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"enable_group_gifting","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tag_recs","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_one_tap","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_dynamic_paywall_programming","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"redefined_top_posts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_iceland_nux","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_in_app_free_trial","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pill_based_home_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_susi_redesign_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_simplified_digest_v2_b","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pre_pp_v4","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_stripe_customers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_premium_tier","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_integration","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mobile_lohp_short_hero","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"enable_recirc_model","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tick_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_home_post_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_newsletter_lo_flow_custom_domains","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_explicit_signals","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_recaptcha_enterprise","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_seamless_social_sharing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_verified_book_author","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_test_auth","valueType":{"__typename":"VariantFlagString","value":"disallow"}},{"__typename":"VariantFlag","name":"mobile_custom_app_icon","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_signup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_automod","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_image_sharer","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_moc_load_processor_c","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pp_v4","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_speechify_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}}],"isLoggedIn":true,"viewer":{"__ref":"User:3a1bd8879bcf"},"collectionByDomainOrSlug({\"domainOrSlug\":\"towardsdatascience.com\"})":{"__ref":"Collection:7f60cf5620c9"},"postResult({\"id\":\"68b2dede498f\"})":{"__ref":"Post:68b2dede498f"}},"UserViewerEdge:userId:3a1bd8879bcf-viewerId:3a1bd8879bcf":{"__typename":"UserViewerEdge","id":"userId:3a1bd8879bcf-viewerId:3a1bd8879bcf","createdAt":1540271780316},"User:3a1bd8879bcf":{"__typename":"User","id":"3a1bd8879bcf","allowEmailAddressSharingEditorWriter":false,"atsQualifiedAt":0,"dismissableFlags":["BLOGROLL_ENABLE","FOLLOWERS_TOOLTIP"],"emailObfuscated":"se•••••••@gmail.com","geolocation":{"__typename":"Geolocation","country":"AR"},"hasGroupGiftingEnabled":false,"hasPastMemberships":false,"hasSubdomain":true,"imageId":"0*pLvuvXRh9wIbC5a8","isEligibleToImportEmails":false,"isEligibleToViewNewResponses":true,"isMembershipTrialEligible":true,"isSuspended":false,"membership":null,"name":"Sebastián López","partnerProgramEnrollment":null,"postSubscribeMembershipUpsellShownAt":0,"styleEditorOnboardingVersionSeen":0,"twitterScreenName":"SebastlopRock","unverifiedEmail":"","username":"sebastlop","viewerEdge":{"__ref":"UserViewerEdge:userId:3a1bd8879bcf-viewerId:3a1bd8879bcf"}},"ImageMetadata:1*VzTUkfeGymHP4Bvav-T-lA.png":{"__typename":"ImageMetadata","id":"1*VzTUkfeGymHP4Bvav-T-lA.png"},"Collection:7f60cf5620c9":{"__typename":"Collection","id":"7f60cf5620c9","favicon":{"__ref":"ImageMetadata:1*VzTUkfeGymHP4Bvav-T-lA.png"},"customStyleSheet":null,"colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}},"googleAnalyticsId":null,"editors":[{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:7e12c71dfa81"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:e6ad8abedec9"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:895063a310f4"}}],"name":"Towards Data Science","avatar":{"__ref":"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg"},"domain":"towardsdatascience.com","slug":"towards-data-science","description":"Your home for data science. A Medium publication sharing concepts, ideas and codes.","subscriberCount":690675,"viewerEdge":{"__ref":"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:3a1bd8879bcf"},"twitterUsername":"TDataScience","facebookPageId":null,"logo":{"__ref":"ImageMetadata:1*cFFKn8rFH4ZndmaYeAs6iQ.png"}},"User:7e12c71dfa81":{"__typename":"User","id":"7e12c71dfa81"},"User:e6ad8abedec9":{"__typename":"User","id":"e6ad8abedec9"},"User:895063a310f4":{"__typename":"User","id":"895063a310f4"},"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg":{"__typename":"ImageMetadata","id":"1*CJe3891yB1A1mzMdqemkdg.jpeg"},"LinkedAccounts:e7f791e64e83":{"__typename":"LinkedAccounts","mastodon":null,"id":"e7f791e64e83"},"UserViewerEdge:userId:e7f791e64e83-viewerId:3a1bd8879bcf":{"__typename":"UserViewerEdge","id":"userId:e7f791e64e83-viewerId:3a1bd8879bcf","isFollowing":false,"isUser":false,"isMuting":false},"NewsletterV3:7c56dcd5dd56":{"__typename":"NewsletterV3","id":"7c56dcd5dd56","type":"NEWSLETTER_TYPE_AUTHOR","slug":"e7f791e64e83","name":"e7f791e64e83","collection":null,"user":{"__ref":"User:e7f791e64e83"}},"User:e7f791e64e83":{"__typename":"User","id":"e7f791e64e83","name":"Daniel Shapiro, PhD","username":"lemaysolutions","newsletterV3":{"__ref":"NewsletterV3:7c56dcd5dd56"},"linkedAccounts":{"__ref":"LinkedAccounts:e7f791e64e83"},"isSuspended":false,"imageId":"1*moqpKxEKi4uSXIhNBwgOkQ.jpeg","mediumMemberAt":1507575859000,"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"socialStats":{"__typename":"SocialStats","followerCount":4817},"customDomainState":null,"hasSubdomain":false,"bio":"Passionate About Machine Learning R&D and Value Creation. ✍ daniel@lemay.ai ⬱ https:\u002F\u002Flemay.ai","isPartnerProgramEnrolled":false,"viewerEdge":{"__ref":"UserViewerEdge:userId:e7f791e64e83-viewerId:3a1bd8879bcf"},"viewerIsUser":false,"postSubscribeMembershipUpsellShownAt":0,"allowNotes":true,"membership":{"__ref":"Membership:25823a5d12dd"},"twitterScreenName":"Lemay_ai"},"Topic:1eca0103fff3":{"__typename":"Topic","slug":"machine-learning","id":"1eca0103fff3","name":"Machine Learning"},"ImageMetadata:1*ojCq-1v1IRSGFq8-0Nflhg.png":{"__typename":"ImageMetadata","id":"1*ojCq-1v1IRSGFq8-0Nflhg.png","originalHeight":274,"originalWidth":956,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:4de31c35c840_0":{"__typename":"Paragraph","id":"4de31c35c840_0","name":"e28d","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*ojCq-1v1IRSGFq8-0Nflhg.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_1":{"__typename":"Paragraph","id":"4de31c35c840_1","name":"1246","type":"H3","href":null,"layout":null,"metadata":null,"text":"Speaker Differentiation Using Deep Learning","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_2":{"__typename":"Paragraph","id":"4de31c35c840_2","name":"2c88","type":"P","href":null,"layout":null,"metadata":null,"text":"Last week, I presented a conference paper at ICSEE2018 on a neural network system with the ability to quickly differentiate between speakers in dual microphone audio. This is related to the cocktail party problem. In my work, the idea is that a neural network learns how to separate voices into bins using a small amount of clean training data for each speaker (a very optimistic assumption). A further simplifying assumption is that there is normal background noise, but not something difficult like background music or loud noises. The hard part here, or depending on your point of view, the easy part, is that there should be minimal preprocessing. The neural network makes predictions on each segment of the audio, and when each of the voice signatures are detected in a given conversation, the speaker is recognized.","hasDropCap":true,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":36,"end":54,"href":"https:\u002F\u002Fwww.ieee.org.il\u002Ficsee-2018\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":190,"end":212,"href":"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=Qj5ltrAFric","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_3":{"__typename":"Paragraph","id":"4de31c35c840_3","name":"fd05","type":"P","href":null,"layout":null,"metadata":null,"text":"In the more general cocktail party problem with multiple speakers, which is much harder, the idea is that these speakers can be recognised because we know who is talking by where they are and how loud they talk. In that scenario, the location of the speakers is relevant, whereas in our work the relative position of people talking to the microphones similar, and so we are focusing in on the speaker’s voice, rather than the voice power or relative location.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*x1CCK7bAT9XUEHzLhVc_gQ.png":{"__typename":"ImageMetadata","id":"1*x1CCK7bAT9XUEHzLhVc_gQ.png","originalHeight":338,"originalWidth":593,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:4de31c35c840_4":{"__typename":"Paragraph","id":"4de31c35c840_4","name":"c708","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*x1CCK7bAT9XUEHzLhVc_gQ.png"},"text":"We used 2 microphones to record human voices.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_5":{"__typename":"Paragraph","id":"4de31c35c840_5","name":"3e62","type":"P","href":null,"layout":null,"metadata":null,"text":"There is other work in this field on extracting features from single and dual microphone signals, and let’s skip over all of that. Our goal was to see if a certain kind of neural network could do the job with only basic preprocessing.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_6":{"__typename":"Paragraph","id":"4de31c35c840_6","name":"1d5e","type":"P","href":null,"layout":null,"metadata":null,"text":"My coauthors Mohamed Asni, Tony Mathew, Dr. Miodrag Bolic, and Leor Grebler worked with me on this paper for a really long time. I feel like it took us about a year. Counting back to the grant and the idea stages, more than a year. The project stretched on from requirements gathering to solution architecture, and then data collection, and finally the development, analysis, drafting, submission of the paper, and presentation at the conference. These things happen slowly. The paper should show up in IEEE Xplore and Google Scholar before you know it.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":13,"end":25,"href":"https:\u002F\u002Fca.linkedin.com\u002Fin\u002Fmohamed-asni","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":40,"end":57,"href":"http:\u002F\u002Fwww.site.uottawa.ca\u002F~mbolic\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":63,"end":75,"href":null,"anchorType":"USER","userId":"136fa39ffeba","linkMetadata":null},{"__typename":"Markup","type":"A","start":503,"end":514,"href":"https:\u002F\u002Fieeexplore.ieee.org\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":519,"end":533,"href":"https:\u002F\u002Fscholar.google.ca\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_7":{"__typename":"Paragraph","id":"4de31c35c840_7","name":"2958","type":"P","href":null,"layout":null,"metadata":null,"text":"At the end of the day, we developed a deep learning solution for differentiating human voices in audio originating from two microphone sources simultaneously. To understand the solution better, let’s briefly talk about autoencoders, convolution, MFCC, and more. I’m not going to cover everything we did in the paper, or present the prior art. Instead I want to give you an idea of what we did from a solution architecture perspective.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_8":{"__typename":"Paragraph","id":"4de31c35c840_8","name":"b1d3","type":"P","href":null,"layout":null,"metadata":null,"text":"An Autoencoder (AE) reduces the dimensions of an input to a latent space representation (the encoder part of an AE) and then attempts to reconstruct the compressed data (the decoder). This encoder-decoder system is meant to compress the input into some lower dimensional latent space that preserves the essential information of the input. Put another way, it can be seen as an automated feature extractor. Convolutional AEs, (CAEs) are based on AEs where convolutional layers are used for encoding\u002Fdecoding, rather than layers in an MLP.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":3,"end":14,"href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FAutoencoder","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":406,"end":431,"href":"https:\u002F\u002Flink.springer.com\u002Fchapter\u002F10.1007%2F978-3-642-21735-7_7","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":455,"end":475,"href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FConvolutional_neural_network","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":520,"end":536,"href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FMultilayer_perceptron","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_9":{"__typename":"Paragraph","id":"4de31c35c840_9","name":"a593","type":"P","href":null,"layout":null,"metadata":null,"text":"So, we used CAE for automatic feature extraction and generation of accurate latent space representations, but we didn’t do that on raw audio. Mel-frequency cepstrum (MFCC) provides a short-term spectral representation of audio features. MFCC is a compact form of the amplitude spectrum representation of audio. It reduces computational cost when used as a preprocessing step for feature extraction, and it is widely known and used for human speech stuff. And so, as shown in the image below, we preprocessed that raw audio into MFCC before classifying it using a CAE.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":142,"end":164,"href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FMel-frequency_cepstrum","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*7e0g4xr9yahoCGjp":{"__typename":"ImageMetadata","id":"0*7e0g4xr9yahoCGjp","originalHeight":275,"originalWidth":347,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:4de31c35c840_10":{"__typename":"Paragraph","id":"4de31c35c840_10","name":"a2fe","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*7e0g4xr9yahoCGjp"},"text":"Single microphone audio preprocessing leading to the AI model’s input","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_11":{"__typename":"Paragraph","id":"4de31c35c840_11","name":"5010","type":"P","href":null,"layout":null,"metadata":null,"text":"The basic aim of this work was to evaluate the CAE’s accuracy as the number of buckets at the network’s output increases. We wanted to do this without heavy preprocessing, using input from two microphone sources simultaneously. Our expectation going into this project was that no matter the size and quality of the dataset, as the number of speakers (buckets) increases, the model’s accuracy would eventually decrease. We expected this because the problem gets harder as more possibilities for the output labels are possible. The intuition is that with 2 speakers you have a 50% chance of guessing right by chance, but with 10 speakers you have only a 10% chance. And so separating out who is talking is harder when it could be one of many people.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_12":{"__typename":"Paragraph","id":"4de31c35c840_12","name":"a64c","type":"P","href":null,"layout":null,"metadata":null,"text":"The following confusion matrix shows the dual microphone result for differentiating between 3 speakers. The system recognised 2 of the 3 speakers 12 tries out of 12, but the third speaker was confused twice for the first speaker and once for the second speaker.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":14,"end":30,"href":"https:\u002F\u002Fscikit-learn.org\u002Fstable\u002Fauto_examples\u002Fmodel_selection\u002Fplot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*wsNeS6xhesiF3nnY":{"__typename":"ImageMetadata","id":"0*wsNeS6xhesiF3nnY","originalHeight":443,"originalWidth":573,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:4de31c35c840_13":{"__typename":"Paragraph","id":"4de31c35c840_13","name":"f22b","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*wsNeS6xhesiF3nnY"},"text":"Confusion matrix for 3 speakers in a dual microphone setup","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_14":{"__typename":"Paragraph","id":"4de31c35c840_14","name":"2620","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s talk a bit more about how the above experiment was performed, and how the CAE was designed. The data was collected using two microphones simultaneously, and saved into separate WAV files. We had to collect our own data, as dual microphone datasets are hard to find. We copied the phrases of a common voice dataset, effectively extending it into the dual microphone domain for our narrow application and small dataset. We recorded with a sampling rate of 44100 Hz, with each audio snippet consisting of a 10 second duration. There was a 47 dB average room noise level across the recordings. In our new recordings, we had 6 speakers under the age of 30, 3 of whom were male and 3 were female. The collected samples were converted to MFCC representation for each microphone signal, so that we could compare single microphone and dual microphone performance.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_15":{"__typename":"Paragraph","id":"4de31c35c840_15","name":"5a27","type":"P","href":null,"layout":null,"metadata":null,"text":"In our system, the decoder (DNN) uses relevant features from the encoded data — the data that was generated by the encoder (CNN) — in order to differentiate speakers in the original audio by placing them within buckets","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*CbyA3KgMF4lui5yQ":{"__typename":"ImageMetadata","id":"0*CbyA3KgMF4lui5yQ","originalHeight":312,"originalWidth":449,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:4de31c35c840_16":{"__typename":"Paragraph","id":"4de31c35c840_16","name":"1e28","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*CbyA3KgMF4lui5yQ"},"text":"Block diagram showing the MFCC input for 2 audio snippets concatenated before entering an encoder, followed by a decoder and a softmax at the output. The width of the output was the same as then number of possible individuals (speakers) in each experiment.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_17":{"__typename":"Paragraph","id":"4de31c35c840_17","name":"d2e0","type":"P","href":null,"layout":null,"metadata":null,"text":"For each experiment we used K-fold cross validation to make sure the results were valid. The results for 1 microphone are shown below.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":28,"end":51,"href":"https:\u002F\u002Fscikit-learn.org\u002Fstable\u002Fauto_examples\u002Fmodel_selection\u002Fplot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*845mRIjAlmT8NuBH":{"__typename":"ImageMetadata","id":"0*845mRIjAlmT8NuBH","originalHeight":439,"originalWidth":635,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:4de31c35c840_18":{"__typename":"Paragraph","id":"4de31c35c840_18","name":"7f65","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*845mRIjAlmT8NuBH"},"text":"Test results for a single microphone (one MFCC input).","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_19":{"__typename":"Paragraph","id":"4de31c35c840_19","name":"3edd","type":"P","href":null,"layout":null,"metadata":null,"text":"And now let’s look at the results for 2 microphones:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*v-UKqhWxOPq0pmfO":{"__typename":"ImageMetadata","id":"0*v-UKqhWxOPq0pmfO","originalHeight":443,"originalWidth":640,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:4de31c35c840_20":{"__typename":"Paragraph","id":"4de31c35c840_20","name":"2a9c","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*v-UKqhWxOPq0pmfO"},"text":"Test results for a dual microphone (two MFCC inputs).","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_21":{"__typename":"Paragraph","id":"4de31c35c840_21","name":"ee91","type":"P","href":null,"layout":null,"metadata":null,"text":"The first thing we notice when comparing single and dual microphone results is that the model performed better when given audio from 2 microphone sources as opposed to a single microphone source. That’s good news. It means our idea to use 2 microphones is not dumb. We also see in both results a degradation in performance as the number of possible speakers (buckets) goes up. As the number of speaker classes increases, the model’s accuracy decreases. Digging for a more general conclusion, we found that a CAE can differentiate speakers in audio, given a small sample size of audio collected from 2 microphones simultaneously.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_22":{"__typename":"Paragraph","id":"4de31c35c840_22","name":"e5bb","type":"P","href":null,"layout":null,"metadata":null,"text":"Hopefully this article gave you a better sense of what the paper was about, what we figured out, and how we did it. This work was generously funded by Natural Sciences and Engineering Research Council of Canada (NSERC) and Unified Computer Intelligence Corporation (UCIC.io). Since this project started, Mohamed has come to work at lemay.ai, and stallion.ai.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":266,"end":273,"href":"http:\u002F\u002Fwww.ucic.io\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":332,"end":340,"href":"http:\u002F\u002Flemay.ai","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":346,"end":357,"href":"https:\u002F\u002Fstallion.ai\u002Fen\u002Fteam","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_23":{"__typename":"Paragraph","id":"4de31c35c840_23","name":"6481","type":"P","href":null,"layout":null,"metadata":null,"text":"It was really useful to attend this biennial IEEE conference. It was more technical than the last conference I went to (TMLS2018 — more on that trip here) and a bit more than one third the size of TMLS. But I did enjoy both conferences. I met some really interesting people, saw some great talks, and I can tell you from this experience that a lot is changing in the signal processing field. There is still excellent feature engineering work going on, and also a whole whack of new papers on ML\u002FAI approaches to speech and signal processing. There were also some excellent talks on the special session on deep learning. Some of the presenters I recognised half way through as people I saw lecturing in youtube videos. It’s like nerdy celebrity watching. Very exciting times.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":36,"end":44,"href":"https:\u002F\u002Fwww.merriam-webster.com\u002Fdictionary\u002Fbiennial","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":120,"end":128,"href":"https:\u002F\u002Ftorontomachinelearning.com\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":149,"end":153,"href":"https:\u002F\u002Ftowardsdatascience.com\u002Fpitching-artificial-intelligence-to-business-people-f8ddd8fb2da2","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_24":{"__typename":"Paragraph","id":"4de31c35c840_24","name":"92a8","type":"P","href":null,"layout":null,"metadata":null,"text":"If you liked this article on my recent paper, then have a look at some of my most read past articles, like “How to Price an AI Project” and “How to Hire an AI Consultant.”","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":108,"end":134,"href":"https:\u002F\u002Fmedium.com\u002Ftowards-data-science\u002Fhow-to-price-an-ai-project-f7270cb630a4","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":141,"end":169,"href":"https:\u002F\u002Fmedium.com\u002Ftowards-data-science\u002Fwhy-hire-an-ai-consultant-50e155e17b39","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_25":{"__typename":"Paragraph","id":"4de31c35c840_25","name":"c4de","type":"P","href":null,"layout":null,"metadata":null,"text":"Until next time!","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_26":{"__typename":"Paragraph","id":"4de31c35c840_26","name":"4755","type":"P","href":null,"layout":null,"metadata":null,"text":"-Daniel","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_27":{"__typename":"Paragraph","id":"4de31c35c840_27","name":"8427","type":"P","href":null,"layout":null,"metadata":null,"text":"Other articles you may enjoy:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_28":{"__typename":"Paragraph","id":"4de31c35c840_28","name":"167e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Artificial Intelligence and Bad Data","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":36,"href":"https:\u002F\u002Ftowardsdatascience.com\u002Fartificial-intelligence-and-bad-data-fbf2564c541a","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_29":{"__typename":"Paragraph","id":"4de31c35c840_29","name":"70d3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Image Datasets for Artificial Intelligence","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":42,"href":"https:\u002F\u002Ftowardsdatascience.com\u002Fimage-datasets-for-artificial-intelligence-bbb12615edd7","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:4de31c35c840_30":{"__typename":"Paragraph","id":"4de31c35c840_30","name":"4172","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Artificial Intelligence: Get your users to label your data","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":58,"href":"https:\u002F\u002Fmedium.com\u002Ftowards-data-science\u002Fartificial-intelligence-get-your-users-to-label-your-data-b5fa7c0c9e00","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:3a1bd8879bcf":{"__typename":"CollectionViewerEdge","id":"collectionId:7f60cf5620c9-viewerId:3a1bd8879bcf","isEditor":false,"isMuting":false},"Membership:25823a5d12dd":{"__typename":"Membership","tier":"MEMBER","id":"25823a5d12dd"},"ImageMetadata:1*cFFKn8rFH4ZndmaYeAs6iQ.png":{"__typename":"ImageMetadata","id":"1*cFFKn8rFH4ZndmaYeAs6iQ.png","originalWidth":2381,"originalHeight":743},"Tag:machine-learning":{"__typename":"Tag","id":"machine-learning","displayTitle":"Machine Learning","normalizedTagSlug":"machine-learning"},"Tag:deep-learning":{"__typename":"Tag","id":"deep-learning","displayTitle":"Deep Learning","normalizedTagSlug":"deep-learning"},"Tag:data-science":{"__typename":"Tag","id":"data-science","displayTitle":"Data Science","normalizedTagSlug":"data-science"},"Tag:artificial-intelligence":{"__typename":"Tag","id":"artificial-intelligence","displayTitle":"Artificial Intelligence","normalizedTagSlug":"artificial-intelligence"},"Tag:towards-data-science":{"__typename":"Tag","id":"towards-data-science","displayTitle":"Towards Data Science","normalizedTagSlug":"towards-data-science"},"Post:68b2dede498f":{"__typename":"Post","id":"68b2dede498f","collection":{"__ref":"Collection:7f60cf5620c9"},"content({\"postMeteringOptions\":{}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"afa6","startIndex":0,"textLayout":"FLOW","imageLayout":"NONE","backgroundImage":null,"videoLayout":"NO_VIDEO","backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:4de31c35c840_0"},{"__ref":"Paragraph:4de31c35c840_1"},{"__ref":"Paragraph:4de31c35c840_2"},{"__ref":"Paragraph:4de31c35c840_3"},{"__ref":"Paragraph:4de31c35c840_4"},{"__ref":"Paragraph:4de31c35c840_5"},{"__ref":"Paragraph:4de31c35c840_6"},{"__ref":"Paragraph:4de31c35c840_7"},{"__ref":"Paragraph:4de31c35c840_8"},{"__ref":"Paragraph:4de31c35c840_9"},{"__ref":"Paragraph:4de31c35c840_10"},{"__ref":"Paragraph:4de31c35c840_11"},{"__ref":"Paragraph:4de31c35c840_12"},{"__ref":"Paragraph:4de31c35c840_13"},{"__ref":"Paragraph:4de31c35c840_14"},{"__ref":"Paragraph:4de31c35c840_15"},{"__ref":"Paragraph:4de31c35c840_16"},{"__ref":"Paragraph:4de31c35c840_17"},{"__ref":"Paragraph:4de31c35c840_18"},{"__ref":"Paragraph:4de31c35c840_19"},{"__ref":"Paragraph:4de31c35c840_20"},{"__ref":"Paragraph:4de31c35c840_21"},{"__ref":"Paragraph:4de31c35c840_22"},{"__ref":"Paragraph:4de31c35c840_23"},{"__ref":"Paragraph:4de31c35c840_24"},{"__ref":"Paragraph:4de31c35c840_25"},{"__ref":"Paragraph:4de31c35c840_26"},{"__ref":"Paragraph:4de31c35c840_27"},{"__ref":"Paragraph:4de31c35c840_28"},{"__ref":"Paragraph:4de31c35c840_29"},{"__ref":"Paragraph:4de31c35c840_30"}]},"validatedShareKey":"","shareKeyCreator":null},"creator":{"__ref":"User:e7f791e64e83"},"inResponseToEntityType":null,"isLocked":false,"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fspeaker-differentiation-using-deep-learning-68b2dede498f","primaryTopic":{"__ref":"Topic:1eca0103fff3"},"topics":[{"__typename":"Topic","slug":"machine-learning"}],"isPublished":true,"latestPublishedVersion":"4de31c35c840","visibility":"PUBLIC","postResponses":{"__typename":"PostResponses","count":1},"createdAt":1544734548336,"firstPublishedAt":1545411183502,"latestPublishedAt":1545411183502,"clapCount":291,"allowResponses":true,"isLimitedState":false,"title":"Speaker Differentiation Using Deep Learning","isSeries":false,"sequence":null,"uniqueSlug":"speaker-differentiation-using-deep-learning-68b2dede498f","socialTitle":"","socialDek":"","noIndex":null,"canonicalUrl":"","metaDescription":"","readingTime":6.1745283018867925,"previewContent":{"__typename":"PreviewContent","subtitle":"Last week, I presented a conference paper at ICSEE2018 on a neural network system with the ability to quickly differentiate between…"},"previewImage":{"__ref":"ImageMetadata:1*ojCq-1v1IRSGFq8-0Nflhg.png"},"isShortform":false,"seoTitle":"","updatedAt":1638842695463,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"","isSuspended":false,"license":"ALL_RIGHTS_RESERVED","tags":[{"__ref":"Tag:machine-learning"},{"__ref":"Tag:deep-learning"},{"__ref":"Tag:data-science"},{"__ref":"Tag:artificial-intelligence"},{"__ref":"Tag:towards-data-science"}],"isNewsletter":false,"statusForCollection":"APPROVED","pendingCollection":null,"detectedLanguage":"en","wordCount":1358,"layerCake":3}}</script><script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/manifest.07913534.js"></script><script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/3057.5e22bbb0.js"></script><script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/main.1fc0c58a.js"></script><script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/instrumentation.4ddbf12e.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/reporting.2021fe63.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/6068.e9093f2e.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/4398.db4d4378.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/7883.0e445e04.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/9281.e9be8bce.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/7111.1421aaa2.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/6481.9389fa5e.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/8695.17d1af21.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/3418.eb013b5a.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/5971.2133e397.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/5514.32e692f6.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/5203.d7ff263d.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/7098.93054372.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/703.79c6106e.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1711.7605eb3e.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/8597.c12400e1.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/9174.1df5a0ac.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/8883.2f95bbf4.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/705.15bf34f2.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/5781.9f2ea9e7.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/8580.feeb2549.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/6046.f9be485b.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/1525.9d7ce475.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/500.9a872e1f.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/9408.8ab2f0e9.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/6605.84e81b15.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/2790.ca0e202b.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/7421.3f94f5ea.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/51.d8fb2684.chunk.js"></script>
<script src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/PostPage.MainContent.44471406.chunk.js"></script><script>window.main();</script><script defer="defer" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/vef91dfe02fce4ee0ad053f6de4f175db1715022073587.es" integrity="sha512-sDIX0kl85v1Cl5tu4WGLZCpH/dV9OHbA4YlKCuCiMmOQIk4buzoYDZSFj+TvC71mOBLh8CDC/REgE0GX0xcbjA==" data-cf-beacon="{&quot;rayId&quot;:&quot;88874825fe5d9b1e&quot;,&quot;version&quot;:&quot;2024.4.1&quot;,&quot;token&quot;:&quot;0b5f665943484354a59c39c6833f7078&quot;}" crossorigin="anonymous"></script>
<div><div class="grecaptcha-badge" data-style="bottomright" style="width: 256px; height: 60px; display: block; transition: right 0.3s; position: fixed; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;"><div class="grecaptcha-logo"><iframe title="reCAPTCHA" width="256" height="60" role="presentation" name="a-j8u1n8xyyzst" frameborder="0" scrolling="no" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox allow-storage-access-by-user-activation" src="Speaker%20Differentiation%20Using%20Deep%20Learning%20by%20Daniel%20Shapiro,%20PhD%20Towards%20Data%20Science_files/anchor.html"></iframe></div><div class="grecaptcha-error"></div><textarea id="g-recaptcha-response-100000" name="g-recaptcha-response" class="g-recaptcha-response" style="width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;"></textarea></div><iframe style="display: none;"></iframe></div></body></html>